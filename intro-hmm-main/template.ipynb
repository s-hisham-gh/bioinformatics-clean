{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ef1f02dc-751c-4e65-b652-fa8109edb115",
      "metadata": {
        "id": "ef1f02dc-751c-4e65-b652-fa8109edb115"
      },
      "source": [
        "# Hidden Markov Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "208d1500-212e-4608-9ea4-384360f24949",
      "metadata": {
        "id": "208d1500-212e-4608-9ea4-384360f24949"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ec2ba0f4-07b8-4837-9e08-c463120d3211",
      "metadata": {
        "id": "ec2ba0f4-07b8-4837-9e08-c463120d3211"
      },
      "outputs": [],
      "source": [
        "from importlib import reload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "13648f68-93d3-4258-bdd4-e32ef25fde5b",
      "metadata": {
        "id": "13648f68-93d3-4258-bdd4-e32ef25fde5b"
      },
      "outputs": [],
      "source": [
        "class HMM(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Hidden Markov model with discrete states and observations.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_hidden, n_observed):\n",
        "        \"\"\"\n",
        "        Initialize model with n_hidden states and n_observed states.\n",
        "        \"\"\"\n",
        "        super(HMM, self).__init__()\n",
        "        self.K = n_hidden\n",
        "        self.V = n_observed\n",
        "        self.prior_module = PriorModule(self.K)\n",
        "        self.transition_module = TransitionModule(self.K)\n",
        "        self.emission_module = EmissionModule(self.K, self.V)\n",
        "\n",
        "        # enable cuda is it is available\n",
        "        # if torch.cuda.is_available():\n",
        "        #     self.cuda()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1432d0dc-0567-40f6-b3d3-50e61cc583d4",
      "metadata": {
        "id": "1432d0dc-0567-40f6-b3d3-50e61cc583d4"
      },
      "source": [
        "### Prior probabilities\n",
        "\n",
        "The prior probability vector $\\boldsymbol{\\alpha}$ is defined as\n",
        "$$\n",
        "\\alpha[k] = P(z_0 = k) .\n",
        "$$\n",
        "\n",
        "Since $P(z_0)$ is probability distribution, it must sum to 1:\n",
        "$$\n",
        "\\sum_{k = 0}^{K - 1} P(z_0 = k) = 1 .\n",
        "$$\n",
        "\n",
        "In order to preserve numerical precision, we store $\\boldsymbol{\\alpha}$ as real values with range from $-\\infty$ to $\\infty$. We name this variable `real_alpha`. Keeping `alpha` in real space also allows us to randomly initialize it using the standard normal distribution.\n",
        "\n",
        "Accordingly, we must normalize `real_alpha` before returning it as the prior probability vector. In other words, we must normalize `real_alpha` such that\n",
        "$$\n",
        "\\sum_{k = 0}^{K - 1} \\alpha[k] = 1 .\n",
        "$$\n",
        "\n",
        "For this, we can use the `torch.nn.functional.softmax` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3df12f49-edc4-4c30-86fe-aecf2b8e3433",
      "metadata": {
        "id": "3df12f49-edc4-4c30-86fe-aecf2b8e3433"
      },
      "outputs": [],
      "source": [
        "class PriorModule(torch.nn.Module):\n",
        "    def __init__(self, K):\n",
        "        \"\"\"\n",
        "        Create prior vector with random initial values.\n",
        "        \"\"\"\n",
        "        super(PriorModule, self).__init__()\n",
        "        self.K = K\n",
        "        self.real_alpha = torch.nn.Parameter(torch.randn(K))\n",
        "\n",
        "    def probs(self):\n",
        "        \"\"\"\n",
        "        Return the prior probability vector.\n",
        "        \"\"\"\n",
        "        return torch.nn.functional.softmax(\n",
        "            self.real_alpha, dim=0 #Essentially, we are normalizing the values in the vector (Making sure they are between 0 and 1)\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aac91483-de49-4075-8bda-9e3938241b87",
      "metadata": {
        "id": "aac91483-de49-4075-8bda-9e3938241b87"
      },
      "source": [
        "### Transition probabilities\n",
        "\n",
        "The transition probability matrix $\\boldsymbol{B}$ is defined such that\n",
        "$$\n",
        "B[k, l] = P(z_{t+1} = l \\mid z_{t} = k) .\n",
        "$$\n",
        "(Note: As per standard mathematical notation, we represent a matrix by an uppercase bold letter. The uppercase of $\\beta$ is $B$.)\n",
        "\n",
        "The `TransitionModule` will store the transition matrix as real values (i.e. their ranges are from $-\\infty$ to $\\infty$. It will normalize the transition matrix.\n",
        "\n",
        "Therefore, this module needs to normalize the `real_Beta` in order to obtain proper probability values; that is, for each hidden state $i$,\n",
        "$$\n",
        "\\sum_{l = 0}^{K-1} P(z_{t+1} = l \\mid z_{t} = k) = 1 .\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f2547a2-4389-4423-a8e5-1f78bee4228a",
      "metadata": {
        "id": "2f2547a2-4389-4423-a8e5-1f78bee4228a"
      },
      "source": [
        "###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "40382080-b383-4fba-8fd4-49d0fc034c39",
      "metadata": {
        "id": "40382080-b383-4fba-8fd4-49d0fc034c39"
      },
      "outputs": [],
      "source": [
        "class TransitionModule(torch.nn.Module):\n",
        "    def __init__(self, K):\n",
        "        \"\"\"\n",
        "        Create transition matrix with K hidden states and random initial values.\n",
        "        \"\"\"\n",
        "        super(TransitionModule, self).__init__()\n",
        "        self.K = K\n",
        "        # sample initial values from standard normal\n",
        "        self.real_Beta = torch.nn.Parameter(torch.randn(K, K)) # Initializing real_Beta with random values sampled from a standard normal distribution\n",
        "\n",
        "    def probs(self):\n",
        "        \"\"\"\n",
        "        Return the transition probability matrix.\n",
        "        \"\"\"\n",
        "        return torch.nn.functional.softmax(self.real_Beta, dim=1) # Applying softmax to real_Beta along the columns to normalize each row"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95d1e697-9f82-41ac-a8f6-df9eada2c6ed",
      "metadata": {
        "id": "95d1e697-9f82-41ac-a8f6-df9eada2c6ed"
      },
      "source": [
        "### Emission probabilities\n",
        "\n",
        "The emission probability matrix $\\boldsymbol{\\Gamma}$ is defined as\n",
        "$$\n",
        "\\Gamma[k, v] = P( x_t = v \\mid z_t = k) .\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0ff72edd-e732-47ab-a56b-12d941a7097b",
      "metadata": {
        "id": "0ff72edd-e732-47ab-a56b-12d941a7097b"
      },
      "outputs": [],
      "source": [
        "class EmissionModule(torch.nn.Module):\n",
        "    def __init__(self, K, V):\n",
        "        \"\"\"\n",
        "        Randomly initialize emission matirx with K hidden states and V observed states.\n",
        "        \"\"\"\n",
        "        super(EmissionModule, self).__init__()\n",
        "        self.real_Gamma = torch.nn.Parameter(torch.randn(K, V)) # Initializing real_Gamma with random values sampled from a standard normal distribution\n",
        "\n",
        "    def probs(self):\n",
        "        \"\"\"\n",
        "        Return the emission probability matrix.\n",
        "        \"\"\"\n",
        "        return torch.nn.functional.softmax(self.real_Gamma, dim=1) # Applying softmax to real_Gamma to normalize\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2be12a61-c7b5-4835-8606-19cfa3a7fb56",
      "metadata": {
        "id": "2be12a61-c7b5-4835-8606-19cfa3a7fb56"
      },
      "source": [
        "### Sampling from the model\n",
        "\n",
        "Once the parameters $(\\boldsymbol{\\alpha}, \\boldsymbol{B}, \\boldsymbol{\\Gamma})$ are fully specified, we can sample from the HMM simply by following the model definition:\n",
        "\n",
        "For $t = 0$,\n",
        "$$\n",
        "\\begin{aligned}\n",
        "z_0 \\; &\\sim \\; \\text{Categorical}( \\boldsymbol{\\alpha} ) , \\\\\n",
        "x_0 \\mid z_0 = k \\; &\\sim \\; \\text{Categorical}( \\boldsymbol{\\gamma}_k ) ,\n",
        "\\end{aligned}\n",
        "$$\n",
        "where $\\boldsymbol{\\gamma}_k$ is the $k$-th row of $\\boldsymbol{\\Gamma}$.\n",
        "\n",
        "For $1 < t < T$,\n",
        "$$\n",
        "\\begin{aligned}\n",
        "z_t \\mid z_{t-1} \\; &\\sim \\; \\text{Categorical}( \\boldsymbol{\\beta}_k ) , \\\\\n",
        "x_t \\mid z_t = k \\; &\\sim \\; \\text{Categorical}( \\boldsymbol{\\gamma}_k ) ,\n",
        "\\end{aligned}\n",
        "$$\n",
        "where $\\boldsymbol{\\beta}_k$ is the $k$-th row of $\\boldsymbol{B}$.\n",
        "\n",
        "We can draw a sample from a categorical distribution using `torch.distributions.categorical.Categorical`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e63b3692-039a-485d-b0a8-b2150a936daa",
      "metadata": {
        "id": "e63b3692-039a-485d-b0a8-b2150a936daa"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sample(self, T=10):\n",
        "    \"\"\"\n",
        "    Sample from the hidden Markov model for T time points.\n",
        "    \"\"\"\n",
        "\n",
        "    from torch.distributions.categorical import Categorical\n",
        "\n",
        "    # obtain normalized probabilities\n",
        "    priors = self.prior_module.probs()\n",
        "    transitions = self.transition_module.probs()\n",
        "    emissions = self.emission_module.probs()\n",
        "\n",
        "    # initialize state arrays\n",
        "    z = np.zeros(T, dtype=np.int8)\n",
        "    x = np.zeros(T, dtype=np.int8)\n",
        "\n",
        "    # sample initial state\n",
        "    z_t = Categorical(priors).sample().item()\n",
        "    z[0] = z_t\n",
        "\n",
        "    for t in range(0, T):\n",
        "        # sample emission\n",
        "        x_t = Categorical(emissions[z_t]).sample().item()\n",
        "        x[t] = x_t\n",
        "\n",
        "        # sample transition\n",
        "        z_t = Categorical(transitions[z[t-1]]).sample().item()\n",
        "        z[t] = z_t\n",
        "\n",
        "    return x, z\n",
        "\n",
        "# add sampling method to HMM class\n",
        "HMM.sample = sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2ab1c511-8829-49fa-9a81-8cd49d9bbc73",
      "metadata": {
        "id": "2ab1c511-8829-49fa-9a81-8cd49d9bbc73"
      },
      "outputs": [],
      "source": [
        "model = HMM(4, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f34c2165-317a-4fa5-b9f0-e1da5a9fc0fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f34c2165-317a-4fa5-b9f0-e1da5a9fc0fb",
        "outputId": "4648e85c-2dc6-4080-a1e3-e95982d3e8c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([2, 2, 3, 0, 2, 1, 1, 3, 5, 0], dtype=int8),\n",
              " array([3, 0, 3, 0, 0, 3, 2, 3, 2, 0], dtype=int8))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c13f3b6d-e2fa-4546-a3be-58217ea3310c",
      "metadata": {
        "id": "c13f3b6d-e2fa-4546-a3be-58217ea3310c"
      },
      "source": [
        "### Learning model parameters\n",
        "\n",
        "You can hard-code HMM parameters to achieve the behaivour that\n",
        "you desire. However, we would typically want to learn the parameters by training our model on data.\n",
        "\n",
        "The PyTorch allows us to minimize a loss function using stochastic gradient descent. Thanks to automatic differentiation, we will not have to analytically derive the gradient equations.\n",
        "\n",
        "All we need to do is to specify and implement a loss function. A sensible objective function is the model evidence $p(\\boldsymbol{x})$ for the observed data $\\boldsymbol{x} = (x_0 \\dots x_{T-1})$.\n",
        "\n",
        "In HMM, the model evidence follows directly from its model specifiction:\n",
        "$$\n",
        "p(\\boldsymbol{x})\n",
        "= \\sum_{\\boldsymbol{z}}\n",
        "  p( \\boldsymbol{x} \\mid \\boldsymbol{z} ) \\;\n",
        "  p( \\boldsymbol{z} )\n",
        "= \\sum_{\\boldsymbol{z}} \\; p(x_0 \\mid z_0) \\, p( z_0 ) \\;\n",
        "  \\prod_{t > 0} p( x_t \\mid z_t ) \\, p( z_t \\mid z_{t-1} )\n",
        "$$\n",
        "\n",
        "We want to *maximize* the model evidence $p(\\boldsymbol{x})$. To avoid numeric underflow, we can work in log scale such that we maximize $\\log p(\\boldsymbol{x}) $, which is mathematically maximizing $p(\\boldsymbol{x})$. Since in PyTorch, we need to *minimize* a loss function, we can therefore define our loss function as\n",
        "$$\n",
        "L_{\\theta}(\\boldsymbol{x}) = - \\log p_{\\theta}(\\boldsymbol{x}) ,\n",
        "$$\n",
        "where we use $\\theta$ to represent the collection of all model parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d3c0de8-b2bb-4f6b-8a7a-b4dcacbd9024",
      "metadata": {
        "id": "9d3c0de8-b2bb-4f6b-8a7a-b4dcacbd9024"
      },
      "source": [
        "The model evidence $p(\\boldsymbol{x})$ for HMM can be efficiently calculated using the dynamic programming algorithm, and in HMM, we call this algorithm the **forward algorithm**.\n",
        "\n",
        "The key idea of the forward algorithm is that we can calculate the following probability efficiently:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "a_{k, t}\n",
        " &\\triangleq p( x_0, \\ldots, x_t, z_t = k) \\\\\n",
        " &= p( x_t \\mid z_t = k) \\;\n",
        "   \\sum_l \\;\n",
        "    p( z_t = k \\mid z_{t-1} = l ) \\,\n",
        "    p( x_0, \\ldots, x_{t-1}, z_{t-1} = l ) \\\\\n",
        " &= \\boldsymbol{\\gamma}_k \\;\n",
        "   \\sum_l \\;\n",
        "    \\beta_{k, l} \\, a_{l, t-1}\n",
        "\\end{aligned}\n",
        "$$\n",
        "And this recursive equation can be calculated efficient using dynamic programming.\n",
        "\n",
        "After we calculate $a_{k,t}$, we can determine the model evidence by\n",
        "$$\n",
        "p(\\boldsymbol{x}) = \\sum_k a_{k, T}\n",
        "$$\n",
        "\n",
        "Again, in order to avoid numeric underflow, we work in log scale.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4f50c6ed-f332-452e-83c9-8ae28797350a",
      "metadata": {
        "id": "4f50c6ed-f332-452e-83c9-8ae28797350a"
      },
      "outputs": [],
      "source": [
        "def forward_algorithm(self, x, T):\n",
        "    \"\"\"\n",
        "    Compute log p(x) for each sample in a batch.\n",
        "\n",
        "    x: IntTensor of shape (batch_size, T_max)\n",
        "    T: IntTensor of shape (batch_size)\n",
        "\n",
        "    x[i, :] contains a sample of input whose length is\n",
        "    specified in T[i]. T_max is the maximum sample length\n",
        "    across all samples in a batch.\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size = x.shape[0]\n",
        "    T_max = x.shape[1]\n",
        "\n",
        "    log_priors = self.prior_module()\n",
        "\n",
        "    log_a = torch.zeros(batch_size, T_max, self.K)\n",
        "    log_a[:, 0, :] = self.emission_module(x[:,0]) + log_priors\n",
        "    for t in range(1, T_max):\n",
        "        log_a[:, t, :] = self.emission_module(x[:,t]) + \\\n",
        "            self.transition_module(log_a[:, t-1, :])\n",
        "\n",
        "    # select the sum for the final time (T - 1)\n",
        "    # (each sample x can have a different T).\n",
        "    log_sums = log_a.logsumexp(dim=2)\n",
        "    log_probs = torch.gather(log_sums, 1, T.view(-1,1) - 1)\n",
        "\n",
        "    return log_probs\n",
        "\n",
        "def prior_module_forward(self):\n",
        "    \"\"\"\n",
        "    Return log prior probability vector.\n",
        "    \"\"\"\n",
        "    return torch.nn.functional.log_softmax(self.real_alpha, dim=0)\n",
        "\n",
        "def transition_module_forward(self, prev_log_a):\n",
        "    \"\"\"\n",
        "    Return log a_{0:(K-1), t} using log a_{0:(K-1), t-1}\n",
        "\n",
        "    prev_log_a : Tensor of shape (batch_size, K); column k is log_a{k, t-1}\n",
        "    \"\"\"\n",
        "    log_probs = torch.nn.functional.log_softmax(self.real_Beta, dim=1)\n",
        "    log_a = log_matmul(log_probs, prev_log_a.transpose(0,1)).transpose(0,1)\n",
        "    return log_a\n",
        "\n",
        "def emission_module_forward(self, x_t):\n",
        "    \"\"\"\n",
        "    Return log emission probabilities p( x_t \\mid z_t) for\n",
        "    observation x_t.\n",
        "    \"\"\"\n",
        "    log_probs = torch.nn.functional.log_softmax(self.real_Gamma, dim=1)\n",
        "    return log_probs[:, x_t].transpose(0,1)\n",
        "\n",
        "def log_matmul(log_A, log_B):\n",
        "\t\"\"\"\n",
        "    Compute log(A B) given log A and log B\n",
        "\n",
        "\tlog_A: m x k\n",
        "\tlog_B: k x n\n",
        "\toutput: m x n matrix\n",
        "\n",
        "    For C = A B, we have\n",
        "\tC_{i,j} = sum_k A_{i,k} x B_{k,j}\n",
        "\n",
        "    Here, we compute log C by\n",
        "\tlog C_{i,j} = logsumexp_k log_A_{i,k} + log_B_{k,j}\n",
        "\t\"\"\"\n",
        "\tm = log_A.shape[0]\n",
        "\tk = log_A.shape[1]\n",
        "\tn = log_B.shape[1]\n",
        "\n",
        "\tlog_A_expanded = torch.reshape(log_A, (m,k,1))\n",
        "\tlog_B_expanded = torch.reshape(log_B, (1,k,n))\n",
        "\n",
        "\telementwise_sum = log_A_expanded + log_B_expanded\n",
        "\tout = torch.logsumexp(elementwise_sum, dim=1)\n",
        "\n",
        "\treturn out\n",
        "\n",
        "PriorModule.forward = prior_module_forward\n",
        "TransitionModule.forward = transition_module_forward\n",
        "EmissionModule.forward = emission_module_forward\n",
        "HMM.forward = forward_algorithm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a49ba1c-85e0-40bd-b22e-8bf41112a712",
      "metadata": {
        "id": "0a49ba1c-85e0-40bd-b22e-8bf41112a712"
      },
      "source": [
        "### Encoding and decoding\n",
        "\n",
        "We will be working with text input, so we need to encode the data appropriately. For HMM, since we only use the encoded values for the purposing of indexing the emission and transition probability matrices, integer encoding is appropriate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6ca0b598-be7a-4dfc-903d-79166fc184df",
      "metadata": {
        "id": "6ca0b598-be7a-4dfc-903d-79166fc184df"
      },
      "outputs": [],
      "source": [
        "def encode(xs):\n",
        "    character_set = string.ascii_lowercase\n",
        "    char_to_index = {ch: idx for idx, ch in enumerate(character_set)}\n",
        "    encoded_xs = [char_to_index[ch.lower()] for ch in xs if ch.lower() in char_to_index]\n",
        "    return encoded_xs\n",
        "\n",
        "def decode(ys, character_set=string.ascii_lowercase):\n",
        "    character_set = string.ascii_lowercase\n",
        "    index_to_char = {idx: ch for idx, ch in enumerate(character_set)}\n",
        "    decoded_string = ''.join(index_to_char[idx] for idx in ys if idx in index_to_char)\n",
        "    return decoded_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ca6fa061-7707-4cd3-b998-a250c7cc9853",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca6fa061-7707-4cd3-b998-a250c7cc9853",
        "outputId": "268d8736-e8e0-412c-fb44-caf990371c26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[7, 8, 3, 3, 4, 13]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encode(\"Hidden\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f47bea11-f618-43d0-b800-a3b3e02cbe70",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f47bea11-f618-43d0-b800-a3b3e02cbe70",
        "outputId": "e6217f74-6c00-4764-bab0-72fea3595774"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hidden'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decode(np.array([7, 8, 3, 3, 4, 13]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "702c047e-ff02-4aae-857b-5e94453cdc6a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "702c047e-ff02-4aae-857b-5e94453cdc6a",
        "outputId": "eed38a56-c45d-48ea-90cd-c1b0d33b0f50"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'baacdccbee'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decode(model.sample()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed942079-e664-4a60-bf59-4a671ca5440b",
      "metadata": {
        "id": "ed942079-e664-4a60-bf59-4a671ca5440b"
      },
      "source": [
        "### Running forward algorithm\n",
        "\n",
        "With the forward algorithm and the encoder/decoder functions implemented, we are now ready to run the forward algorithm to calculate the log model evidence. This should output a floating value that is usually negative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "41dd4022-b823-4209-a0a0-ad08d99e7f5e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41dd4022-b823-4209-a0a0-ad08d99e7f5e",
        "outputId": "a8628188-1f7b-4949-8883-6c7d105bb6d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-9.8939]], grad_fn=<GatherBackward0>)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.stack( [torch.tensor(encode(\"cat\"))] )\n",
        "T = torch.tensor([3])\n",
        "\n",
        "model = HMM(n_hidden=2, n_observed=26)\n",
        "\n",
        "model.forward(x, T)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bfbc568-2693-45ef-9c9f-8271b07ff0ae",
      "metadata": {
        "id": "6bfbc568-2693-45ef-9c9f-8271b07ff0ae"
      },
      "source": [
        "Now that we have successfully implemented the forward pass in PyTorch, we can take advantage of its automatic differentiation capability to optimize our objective function by stochastic gradient descent. No mathematical derivation needed!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82487fb8-708d-455c-ba40-b6a5495ed2a7",
      "metadata": {
        "id": "82487fb8-708d-455c-ba40-b6a5495ed2a7"
      },
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ad1c3dce-2e39-467a-bfac-b97bd989a537",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad1c3dce-2e39-467a-bfac-b97bd989a537",
        "outputId": "bb48da0f-8151-4b6c-c904-481dc16d828a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 4135k  100 4135k    0     0  3119k      0  0:00:01  0:00:01 --:--:-- 3119k\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p data\n",
        "!curl -L -o data/words.txt https://github.com/dwyl/english-words/raw/master/words_alpha.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "419225c7-6a16-451e-8aa3-a2e7ba9d7634",
      "metadata": {
        "id": "419225c7-6a16-451e-8aa3-a2e7ba9d7634"
      },
      "outputs": [],
      "source": [
        "import utils.preprocess as pp\n",
        "reload(pp)\n",
        "\n",
        "in_fname = \"data/words.txt\"\n",
        "\n",
        "with open(in_fname, \"r\") as f:\n",
        "  words_all = [x.rstrip() for x in f.readlines()]\n",
        "\n",
        "# use only words that begin with 'q' in order to reduce training time\n",
        "words = []\n",
        "for word in words_all:\n",
        "    if word[0] == 'q':\n",
        "        words.append(word)\n",
        "\n",
        "# split data into training and testing\n",
        "train_words, valid_words = train_test_split(words, test_size=0.1, random_state=1)\n",
        "train_dataset = pp.TextDataset(train_words, encode)\n",
        "valid_dataset = pp.TextDataset(valid_words, encode)\n",
        "\n",
        "# construct character set\n",
        "character_set = list(pp.Counter((\"\".join(words))).keys())\n",
        "n_observed = len(character_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "bb1185a5-097f-4cbd-9815-928c95cc068f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb1185a5-097f-4cbd-9815-928c95cc068f",
        "outputId": "8e979d1e-7264-429e-cef8-209e44e1d7d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['quixotically',\n",
              " 'quadruplicity',\n",
              " 'quadriplicated',\n",
              " 'quadriplegia',\n",
              " 'quincentenary']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_words[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "aaea7f1e-ef1d-4a39-80a1-6f6e04236877",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaea7f1e-ef1d-4a39-80a1-6f6e04236877",
        "outputId": "ddec052d-c410-4112-8e0e-61f8650313f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['qual', 'quirite', 'quatorzes', 'quantizable', 'quebracho']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_words[0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9ada1a7-1f96-4fb6-b1f8-a72ac3f64868",
      "metadata": {
        "id": "f9ada1a7-1f96-4fb6-b1f8-a72ac3f64868"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "acf5676a-f71c-4862-bac1-fa485e02a1a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acf5676a-f71c-4862-bac1-fa485e02a1a1",
        "outputId": "2429a582-a1f3-40a2-8caa-b90d22b8a719"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========= Epoch 1 of 10 =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 31.077190399169922\n",
            "twzsfyuyip\n",
            "[3 0 2 1 1 1 1 2 1 1]\n",
            "hqibhwyxlq\n",
            "[2 1 1 2 2 1 1 1 2 3]\n",
            "zboohoasiy\n",
            "[3 3 3 0 3 3 3 1 3 3]\n",
            "qyprpyqijz\n",
            "[3 0 2 0 1 1 1 0 0 2]\n",
            "ruvhogkyug"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            " 46%|████▌     | 6/13 [00:00<00:00, 22.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[2 3 0 3 3 2 1 3 3 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13/13 [00:00<00:00, 26.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 30.830371856689453\n",
            "uomyyiwuis\n",
            "[3 1 1 1 0 3 3 1 0 3]\n",
            "========= Results: epoch 1 of 10 =========\n",
            "train loss: 30.22| valid loss: 31.34\n",
            "\n",
            "========= Epoch 2 of 10 =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 1/13 [00:00<00:01,  8.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 30.218198776245117\n",
            "uyyhvnajjp\n",
            "[3 3 0 2 2 3 1 2 2 0]\n",
            "xmyxbjzlzb\n",
            "[3 1 2 1 1 0 0 3 1 0]\n",
            "iwqitpyyqx\n",
            "[3 0 0 2 1 1 1 1 1 3]\n",
            "qqyofauerp\n",
            "[2 1 3 1 3 1 3 0 2 2]\n",
            "ipqurtrlnb\n",
            "[3 2 1 0 3 3 0 3 2 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13/13 [00:00<00:00, 28.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 30.07282257080078\n",
            "uwfoauaajl\n",
            "[3 0 3 0 3 1 3 1 1 1]\n",
            "========= Results: epoch 2 of 10 =========\n",
            "train loss: 29.11| valid loss: 30.29\n",
            "\n",
            "========= Epoch 3 of 10 =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 1/13 [00:00<00:01,  8.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 27.671920776367188\n",
            "ivfyjidrgu\n",
            "[3 0 3 3 0 3 0 3 3 3]\n",
            "iuwuzjgyje\n",
            "[0 3 1 0 2 2 2 1 0 3]\n",
            "imyiqmkkqa\n",
            "[3 2 2 2 0 0 1 2 3 2]\n",
            "tgrozjawzn\n",
            "[3 0 3 0 3 0 3 0 3 3]\n",
            "tnticuyhfj\n",
            "[3 1 2 1 3 3 0 2 0 2]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13/13 [00:00<00:00, 32.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 30.218486785888672\n",
            "qutiwojlxw\n",
            "[3 2 2 0 3 2 1 0 3 3]\n",
            "========= Results: epoch 3 of 10 =========\n",
            "train loss: 28.18| valid loss: 29.43\n",
            "\n",
            "========= Epoch 4 of 10 =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 2/13 [00:00<00:00, 18.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 26.005043029785156\n",
            "ngqnyrtypi\n",
            "[3 2 2 1 0 2 1 2 0 3]\n",
            "uzdnugtyqw\n",
            "[3 0 2 1 2 2 1 2 2 1]\n",
            "qjeeioqyqu\n",
            "[0 3 0 0 3 2 1 2 3 0]\n",
            "rywupyiitg\n",
            "[3 2 0 0 3 0 0 0 3 2]\n",
            "lmqetrcrsq\n",
            "[3 2 3 0 3 0 0 3 2 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13/13 [00:00<00:00, 45.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 29.124326705932617\n",
            "diprwilqwm\n",
            "[0 0 0 3 0 3 1 3 0 3]\n",
            "========= Results: epoch 4 of 10 =========\n",
            "train loss: 27.42| valid loss: 28.71\n",
            "\n",
            "========= Epoch 5 of 10 =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 3/13 [00:00<00:00, 26.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 26.787975311279297\n",
            "qajtiroweu\n",
            "[3 3 2 1 0 3 2 0 3 0]\n",
            "rylismaaer\n",
            "[3 1 0 3 0 3 3 3 0 3]\n",
            "iauyuisxil\n",
            "[3 0 3 2 2 2 2 2 1 2]\n",
            "iraxliyetu\n",
            "[0 3 1 1 1 1 3 0 3 3]\n",
            "roiiixavym\n",
            "[3 0 0 0 0 3 3 3 0 0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13/13 [00:00<00:00, 43.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 28.353164672851562\n",
            "roaaaevqen\n",
            "[3 0 3 2 2 2 2 2 1 0]\n",
            "========= Results: epoch 5 of 10 =========\n",
            "train loss: 26.79| valid loss: 28.09\n",
            "\n",
            "========= Epoch 6 of 10 =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 2/13 [00:00<00:00, 19.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 25.975135803222656\n",
            "mlatvitisi\n",
            "[3 3 0 3 1 1 1 2 0 3]\n",
            "fggrnannip\n",
            "[0 3 0 0 3 2 2 1 2 1]\n",
            "ijiyapxmns\n",
            "[3 0 3 1 2 1 1 1 2 0]\n",
            "xurnlaulll\n",
            "[3 0 3 2 1 3 1 1 0 3]\n",
            "tadwxhiufq\n",
            "[3 3 3 2 1 2 1 1 1 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13/13 [00:00<00:00, 45.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 27.170148849487305\n",
            "alenntweur\n",
            "[0 3 3 2 0 3 1 3 0 3]\n",
            "========= Results: epoch 6 of 10 =========\n",
            "train loss: 26.23| valid loss: 27.54\n",
            "\n",
            "========= Epoch 7 of 10 =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 3/13 [00:00<00:00, 26.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 25.065462112426758\n",
            "njoaklllqb\n",
            "[0 3 3 0 3 1 1 2 1 2]\n",
            "qafuusqltu\n",
            "[3 2 2 1 1 2 1 0 3 3]\n",
            "liaywqoiei\n",
            "[0 3 0 3 2 3 0 3 0 3]\n",
            "lyerrfuith\n",
            "[1 1 0 0 0 0 0 0 3 0]\n",
            "iryyifnjcw\n",
            "[3 1 2 1 0 3 1 0 3 2]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13/13 [00:00<00:00, 45.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 26.461307525634766\n",
            "qynfeyruud\n",
            "[3 1 2 2 3 0 3 3 2 2]\n",
            "========= Results: epoch 7 of 10 =========\n",
            "train loss: 25.72| valid loss: 27.03\n",
            "\n",
            "========= Epoch 8 of 10 =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 2/13 [00:00<00:00, 18.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 24.702861785888672\n",
            "qnhbiufemu\n",
            "[3 2 1 0 3 2 1 0 3 2]\n",
            "dziyscigiu\n",
            "[3 0 3 0 0 0 3 2 3 0]\n",
            "zuiqigutsi\n",
            "[3 0 0 0 3 1 0 3 0 3]\n",
            "epgyfqnour\n",
            "[2 3 2 3 2 2 3 3 0 3]\n",
            "pqitfcreao\n",
            "[2 1 2 2 1 0 3 3 2 0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13/13 [00:00<00:00, 44.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 26.06682586669922\n",
            "fuhaxxacei\n",
            "[3 2 1 2 0 0 0 0 3 3]\n",
            "========= Results: epoch 8 of 10 =========\n",
            "train loss: 25.25| valid loss: 26.59\n",
            "\n",
            "========= Epoch 9 of 10 =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 3/13 [00:00<00:00, 28.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 25.380290985107422\n",
            "elninfuyma\n",
            "[0 3 0 3 2 1 1 0 3 3]\n",
            "qneisnniey\n",
            "[3 3 1 0 3 2 0 3 3 0]\n",
            "qyewmayemc\n",
            "[3 3 2 0 3 2 3 0 3 3]\n",
            "xrmmqbuiio\n",
            "[0 0 3 2 0 3 1 2 1 0]\n",
            "tsuxaqutui\n",
            "[3 2 2 3 2 1 0 3 2 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13/13 [00:00<00:00, 45.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 26.215030670166016\n",
            "ioeneciuyu\n",
            "[3 0 3 3 3 2 1 1 2 0]\n",
            "========= Results: epoch 9 of 10 =========\n",
            "train loss: 24.85| valid loss: 26.20\n",
            "\n",
            "========= Epoch 10 of 10 =========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 3/13 [00:00<00:00, 26.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 24.936466217041016\n",
            "anooutlisa\n",
            "[1 1 0 3 2 1 0 3 3 2]\n",
            "iirneyqrfn\n",
            "[0 0 3 2 1 2 3 2 1 0]\n",
            "ufinmtauua\n",
            "[0 0 3 2 0 3 2 0 0 3]\n",
            "fclttlruqu\n",
            "[1 1 2 0 0 0 3 2 3 0]\n",
            "iyrudebqwn\n",
            "[3 0 3 3 0 3 2 1 2 2]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13/13 [00:00<00:00, 47.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 25.76019859313965\n",
            "qsamqcdtlq\n",
            "[0 3 3 2 1 3 2 1 2 3]\n",
            "========= Results: epoch 10 of 10 =========\n",
            "train loss: 24.50| valid loss: 25.85\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from utils import train\n",
        "\n",
        "reload(train)\n",
        "\n",
        "model = HMM(4, n_observed=n_observed)\n",
        "\n",
        "# number of training passes through the data\n",
        "n_epochs = 10\n",
        "trainer = train.Trainer(model, learning_rate=0.01)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    print(\"========= Epoch %d of %d =========\" % (epoch+1, n_epochs))\n",
        "    train_loss = trainer.train(train_dataset, decode)\n",
        "    valid_loss = trainer.test(valid_dataset, decode)\n",
        "\n",
        "    print(\"========= Results: epoch %d of %d =========\" % (epoch+1, n_epochs))\n",
        "    print(\"train loss: %.2f| valid loss: %.2f\\n\" % (train_loss, valid_loss) )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b65855c-31a3-40d8-b431-09e3adea0820",
      "metadata": {
        "id": "3b65855c-31a3-40d8-b431-09e3adea0820"
      },
      "source": [
        "### Examining the trained model\n",
        "\n",
        "We can examine the trained model by sampling a few words from it. We need to decode the output in order to read it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "27b8a288-ca70-4f14-9128-db7951c46d29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27b8a288-ca70-4f14-9128-db7951c46d29",
        "outputId": "829fa5bb-7899-40b3-8718-1d3893330267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x: ruqyqsimqu , z: [3 2 3 2 3 0 3 0 3 0]\n",
            "x: zaatyfnvuu , z: [0 0 3 1 0 3 2 3 3 0]\n",
            "x: qulsnqufmi , z: [3 0 3 3 2 2 2 1 0 0]\n",
            "x: qvqtnqrefn , z: [3 2 0 3 2 0 3 3 2 2]\n",
            "x: qaoidkrmyf , z: [3 3 2 0 0 0 0 3 2 1]\n",
            "x: xaddunynqq , z: [3 0 3 2 0 3 3 2 2 0]\n",
            "x: tsriueaqqi , z: [0 0 0 3 0 3 2 1 1 2]\n",
            "x: caitopramz , z: [3 1 0 3 2 0 3 2 3 0]\n",
            "x: jsereieulv , z: [0 0 0 3 2 0 3 1 2 2]\n",
            "x: icqefymzqu , z: [3 0 3 2 1 0 3 2 1 0]\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    s = model.sample()\n",
        "    print(\n",
        "        \"x:\", decode(s[0]),\n",
        "        \", z:\", s[1]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae088f48-e516-46df-a540-ef1188fe23c5",
      "metadata": {
        "id": "ae088f48-e516-46df-a540-ef1188fe23c5"
      },
      "source": [
        "### Questions\n",
        "\n",
        "1. How do you know whether the training is complete?\n",
        "2. Is it better to have more or fewer hidden states in the HMM? Why?\n",
        "3. How can you improve the model further?\n",
        "\n",
        "### Bonus Questions\n",
        "\n",
        "4. Train a HMM to learn the restriction endonuclease\n",
        "   recognition sequences from [New England Biolabs][1].\n",
        "   You will need to preprocess the data appropriately.\n",
        "\n",
        "5. Implement the Viterbi algorithm.\n",
        "   (Hint: it is very similar to the forward algorithm.)\n",
        "\n",
        "[1]: https://www.neb.com/en/tools-and-resources/selection-charts/alphabetized-list-of-recognition-specificities"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aogBPcw_cVaW",
      "metadata": {
        "id": "aogBPcw_cVaW"
      },
      "source": [
        "**Answer 1.** The training is completed when the specified number of epcochs (in our case 10) is reached. Also essentially the changes in loss and accuracy tends to be very minor in between epochs when training is almost done.\n",
        "\n",
        "**Answer 2.** More hidden states can capture more complex patterns but might make the model overfit the data, so rather we should increase the hidden states to a limit, else there is risk of overfitting. And to litte hidden states can result in underfitting.\n",
        "\n",
        "**Answer 3.** We can increase the training data, also perhaps better clean data can be utilised. We can also try to use different hidden layer 'counts' to check which one tends to give us better results. Also we can perhaps decrease the learning rate (although at on point the learning rate may stop effecting the perfomance, or even effect it negativly)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "undefined.undefined.undefined"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
