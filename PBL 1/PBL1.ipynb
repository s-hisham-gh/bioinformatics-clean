{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing the required preprocessing and model selection modules from scikit-learn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importing the ensemble, neighbors, linear model, and tree-based classifiers from scikit-learn\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Importing performance metrics from scikit-learn\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "\n",
    "# Ignoring warning messages to keep the notebook clean\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Reading in the data and transposing it so that the categories are in columns rather than rows.\n",
    "2. Encoding the categorical columns.\n",
    "3. Checking for NaN values and using KNN Imputation to fill them (https://www.analyticsvidhya.com/blog/2020/07/knnimputer-a-robust-way-to-impute-missing-values-using-scikit-learn/).\n",
    "4. Scaling all the columns in the dataset.\n",
    "5. Combining the technical replicates 'left' and 'right' by taking the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the xls data\n",
    "df_left = pd.read_excel('GSE27293_rawdata.xls', sheet_name='left', header=None)\n",
    "df_right = pd.read_excel('GSE27293_rawdata.xls', sheet_name='right', header=None)\n",
    "\n",
    "# Transposing the data so that the categories are in columns rather than rows.\n",
    "df_left = df_left.transpose()\n",
    "df_right = df_right.transpose()\n",
    "df_left.columns = df_left.iloc[0] # Setting the column names to the first row\n",
    "df_right.columns = df_right.iloc[0]\n",
    "df_left = df_left.drop(df_left.index[0]) # Dropping the first row, as its a duplicate of the column names\n",
    "df_right = df_right.drop(df_right.index[0])\n",
    "df_right.columns = df_right.columns.astype(str) # Converting the column names to strings\n",
    "df_left.columns = df_left.columns.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding the 'label' column\n",
    "label_encoder = LabelEncoder()\n",
    "df_left['label'] = label_encoder.fit_transform(df_left['label'])\n",
    "df_right['label'] = label_encoder.fit_transform(df_right['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in left data: 1918\n",
      "Null values in right data: 1918\n"
     ]
    }
   ],
   "source": [
    "# Checking for null values\n",
    "print(\"Null values in left data: \" + str(df_left.isnull().sum().sum()))\n",
    "print(\"Null values in right data: \" + str(df_right.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No null values in data\n"
     ]
    }
   ],
   "source": [
    "# Drop the ID column before imputation\n",
    "id_left = df_left['ID']\n",
    "id_right = df_right['ID']\n",
    "df_left = df_left.drop('ID', axis=1)\n",
    "df_right = df_right.drop('ID', axis=1)\n",
    "\n",
    "# Perform KNN imputation\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "df_left = pd.DataFrame(imputer.fit_transform(df_left), columns=df_left.columns)\n",
    "df_right = pd.DataFrame(imputer.fit_transform(df_right), columns=df_right.columns)\n",
    "\n",
    "# Add the ID column back\n",
    "df_left['ID'] = id_left\n",
    "df_right['ID'] = id_right\n",
    "\n",
    "# Dropping any rows wich still have null values (incase they were not imputed)\n",
    "df_left = df_left.dropna()\n",
    "df_right = df_right.dropna()\n",
    "\n",
    "if df_left.isnull().sum().sum() == 0 and df_right.isnull().sum().sum() == 0:\n",
    "    print(\"No null values in data\")\n",
    "else:\n",
    "    print(\"Null values in left data: \" + str(df_left.isnull().sum().sum()))\n",
    "    print(\"Null values in right data: \" + str(df_right.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_average = pd.DataFrame()\n",
    "df_average['ID'] = df_left['ID']\n",
    "df_average['label'] = df_left['label']\n",
    "\n",
    "for i in range(1, len(df_left.columns)-1):\n",
    "    df_average[df_left.columns[i]] = (df_left.iloc[:, i] + df_right.iloc[:, i]) / 2\n",
    "\n",
    "# Saving Feature column names in a list (All columns except the ID and label columns)\n",
    "feature_cols = df_average.columns\n",
    "feature_cols = feature_cols.drop('ID')\n",
    "feature_cols = feature_cols.drop('label')\n",
    "\n",
    "# Scaling all the feature columns\n",
    "scaler = StandardScaler()\n",
    "df_average[feature_cols] = scaler.fit_transform(df_average[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>TCR a/b</th>\n",
       "      <th>TCR g/d</th>\n",
       "      <th>1a</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>mIgG1 50</th>\n",
       "      <th>mIgG 2a500</th>\n",
       "      <th>mIgG 2a200</th>\n",
       "      <th>mIgG 2a50</th>\n",
       "      <th>mIgG 2b500</th>\n",
       "      <th>mIgG 2b200</th>\n",
       "      <th>mIgG3 500</th>\n",
       "      <th>mIgM 500</th>\n",
       "      <th>mIgM 200</th>\n",
       "      <th>mIgM 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X120571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.398132</td>\n",
       "      <td>-0.034405</td>\n",
       "      <td>-0.123936</td>\n",
       "      <td>0.923793</td>\n",
       "      <td>0.090607</td>\n",
       "      <td>0.900269</td>\n",
       "      <td>1.106923</td>\n",
       "      <td>1.221352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348068</td>\n",
       "      <td>1.643535</td>\n",
       "      <td>1.153839</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>-0.154414</td>\n",
       "      <td>0.176554</td>\n",
       "      <td>2.158845</td>\n",
       "      <td>-0.219046</td>\n",
       "      <td>-0.219564</td>\n",
       "      <td>0.087864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X120664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.169596</td>\n",
       "      <td>-0.440419</td>\n",
       "      <td>-0.398743</td>\n",
       "      <td>-0.512927</td>\n",
       "      <td>-0.047225</td>\n",
       "      <td>-1.242304</td>\n",
       "      <td>-0.049575</td>\n",
       "      <td>-0.616968</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.403407</td>\n",
       "      <td>-0.408805</td>\n",
       "      <td>-0.542215</td>\n",
       "      <td>-0.515366</td>\n",
       "      <td>-0.288721</td>\n",
       "      <td>-0.425354</td>\n",
       "      <td>-0.472939</td>\n",
       "      <td>-0.390700</td>\n",
       "      <td>-0.361668</td>\n",
       "      <td>-0.473861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X120554</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.707311</td>\n",
       "      <td>0.733600</td>\n",
       "      <td>2.941228</td>\n",
       "      <td>0.274146</td>\n",
       "      <td>0.377522</td>\n",
       "      <td>0.527746</td>\n",
       "      <td>0.025075</td>\n",
       "      <td>0.204961</td>\n",
       "      <td>...</td>\n",
       "      <td>1.811335</td>\n",
       "      <td>-0.137142</td>\n",
       "      <td>0.585845</td>\n",
       "      <td>0.394289</td>\n",
       "      <td>0.838871</td>\n",
       "      <td>0.189852</td>\n",
       "      <td>2.745749</td>\n",
       "      <td>0.127628</td>\n",
       "      <td>0.260724</td>\n",
       "      <td>0.375190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X121995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.589307</td>\n",
       "      <td>-0.426029</td>\n",
       "      <td>-0.538671</td>\n",
       "      <td>-1.298864</td>\n",
       "      <td>-0.948758</td>\n",
       "      <td>-0.771570</td>\n",
       "      <td>-1.052179</td>\n",
       "      <td>-0.912552</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.371166</td>\n",
       "      <td>-0.410412</td>\n",
       "      <td>-0.553066</td>\n",
       "      <td>-0.485963</td>\n",
       "      <td>-0.277843</td>\n",
       "      <td>-0.437998</td>\n",
       "      <td>-0.331662</td>\n",
       "      <td>-0.311161</td>\n",
       "      <td>-0.313198</td>\n",
       "      <td>-0.399826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X87355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.001010</td>\n",
       "      <td>-0.426456</td>\n",
       "      <td>-0.398953</td>\n",
       "      <td>-1.746348</td>\n",
       "      <td>-1.431170</td>\n",
       "      <td>-1.529034</td>\n",
       "      <td>-1.594251</td>\n",
       "      <td>-1.834305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.425418</td>\n",
       "      <td>-0.414029</td>\n",
       "      <td>-0.553066</td>\n",
       "      <td>-0.515366</td>\n",
       "      <td>-0.254830</td>\n",
       "      <td>-0.469172</td>\n",
       "      <td>-0.464866</td>\n",
       "      <td>-0.379008</td>\n",
       "      <td>0.226988</td>\n",
       "      <td>-0.368097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>X120198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.779050</td>\n",
       "      <td>-0.323806</td>\n",
       "      <td>-0.116572</td>\n",
       "      <td>0.315033</td>\n",
       "      <td>0.262194</td>\n",
       "      <td>0.866403</td>\n",
       "      <td>0.340901</td>\n",
       "      <td>0.522583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053244</td>\n",
       "      <td>-0.327929</td>\n",
       "      <td>-0.158892</td>\n",
       "      <td>-0.495381</td>\n",
       "      <td>-0.098557</td>\n",
       "      <td>-0.090718</td>\n",
       "      <td>-0.076557</td>\n",
       "      <td>-0.340390</td>\n",
       "      <td>-0.296950</td>\n",
       "      <td>-0.359577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>X121929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363229</td>\n",
       "      <td>0.091588</td>\n",
       "      <td>-0.011783</td>\n",
       "      <td>0.143535</td>\n",
       "      <td>0.450658</td>\n",
       "      <td>0.181186</td>\n",
       "      <td>0.462638</td>\n",
       "      <td>0.018276</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.443089</td>\n",
       "      <td>-0.414029</td>\n",
       "      <td>-0.514254</td>\n",
       "      <td>-0.512609</td>\n",
       "      <td>-0.288721</td>\n",
       "      <td>-0.456528</td>\n",
       "      <td>-0.468095</td>\n",
       "      <td>-0.405757</td>\n",
       "      <td>-0.357675</td>\n",
       "      <td>-0.472098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>X120013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.203340</td>\n",
       "      <td>-0.452784</td>\n",
       "      <td>-0.521838</td>\n",
       "      <td>-0.699189</td>\n",
       "      <td>-0.750449</td>\n",
       "      <td>-1.135062</td>\n",
       "      <td>-0.904028</td>\n",
       "      <td>-0.338238</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442469</td>\n",
       "      <td>-0.411719</td>\n",
       "      <td>-0.489422</td>\n",
       "      <td>0.433340</td>\n",
       "      <td>-0.288721</td>\n",
       "      <td>0.095893</td>\n",
       "      <td>0.201960</td>\n",
       "      <td>-0.361471</td>\n",
       "      <td>-0.361668</td>\n",
       "      <td>-0.459465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>X120677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.605249</td>\n",
       "      <td>-0.251323</td>\n",
       "      <td>-0.560134</td>\n",
       "      <td>-0.328936</td>\n",
       "      <td>-0.404463</td>\n",
       "      <td>-0.253424</td>\n",
       "      <td>-0.081731</td>\n",
       "      <td>-0.268232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.211198</td>\n",
       "      <td>3.594603</td>\n",
       "      <td>4.204567</td>\n",
       "      <td>-0.267738</td>\n",
       "      <td>-0.263408</td>\n",
       "      <td>-0.470698</td>\n",
       "      <td>-0.442666</td>\n",
       "      <td>1.291473</td>\n",
       "      <td>-0.306451</td>\n",
       "      <td>-0.455058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>X110346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.203141</td>\n",
       "      <td>-0.384884</td>\n",
       "      <td>-0.345507</td>\n",
       "      <td>0.158300</td>\n",
       "      <td>-0.314450</td>\n",
       "      <td>-0.708354</td>\n",
       "      <td>0.209977</td>\n",
       "      <td>0.411091</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396897</td>\n",
       "      <td>-0.366910</td>\n",
       "      <td>-0.283050</td>\n",
       "      <td>-0.515366</td>\n",
       "      <td>-0.274077</td>\n",
       "      <td>-0.463940</td>\n",
       "      <td>-0.354267</td>\n",
       "      <td>-0.329407</td>\n",
       "      <td>-0.309205</td>\n",
       "      <td>-0.473861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  label   TCR a/b   TCR g/d        1a         2         3  \\\n",
       "1   X120571    1.0  1.398132 -0.034405 -0.123936  0.923793  0.090607   \n",
       "2   X120664    1.0 -1.169596 -0.440419 -0.398743 -0.512927 -0.047225   \n",
       "3   X120554    1.0  0.707311  0.733600  2.941228  0.274146  0.377522   \n",
       "4   X121995    1.0 -0.589307 -0.426029 -0.538671 -1.298864 -0.948758   \n",
       "5    X87355    1.0 -1.001010 -0.426456 -0.398953 -1.746348 -1.431170   \n",
       "..      ...    ...       ...       ...       ...       ...       ...   \n",
       "79  X120198    0.0  0.779050 -0.323806 -0.116572  0.315033  0.262194   \n",
       "80  X121929    0.0  0.363229  0.091588 -0.011783  0.143535  0.450658   \n",
       "81  X120013    0.0 -1.203340 -0.452784 -0.521838 -0.699189 -0.750449   \n",
       "82  X120677    0.0 -0.605249 -0.251323 -0.560134 -0.328936 -0.404463   \n",
       "83  X110346    0.0 -1.203141 -0.384884 -0.345507  0.158300 -0.314450   \n",
       "\n",
       "           4         5         7  ...  mIgG1 50  mIgG 2a500  mIgG 2a200  \\\n",
       "1   0.900269  1.106923  1.221352  ...  0.348068    1.643535    1.153839   \n",
       "2  -1.242304 -0.049575 -0.616968  ... -0.403407   -0.408805   -0.542215   \n",
       "3   0.527746  0.025075  0.204961  ...  1.811335   -0.137142    0.585845   \n",
       "4  -0.771570 -1.052179 -0.912552  ... -0.371166   -0.410412   -0.553066   \n",
       "5  -1.529034 -1.594251 -1.834305  ... -0.425418   -0.414029   -0.553066   \n",
       "..       ...       ...       ...  ...       ...         ...         ...   \n",
       "79  0.866403  0.340901  0.522583  ...  0.053244   -0.327929   -0.158892   \n",
       "80  0.181186  0.462638  0.018276  ... -0.443089   -0.414029   -0.514254   \n",
       "81 -1.135062 -0.904028 -0.338238  ... -0.442469   -0.411719   -0.489422   \n",
       "82 -0.253424 -0.081731 -0.268232  ... -0.211198    3.594603    4.204567   \n",
       "83 -0.708354  0.209977  0.411091  ... -0.396897   -0.366910   -0.283050   \n",
       "\n",
       "    mIgG 2a50  mIgG 2b500  mIgG 2b200  mIgG3 500  mIgM 500  mIgM 200   mIgM 50  \n",
       "1    0.068100   -0.154414    0.176554   2.158845 -0.219046 -0.219564  0.087864  \n",
       "2   -0.515366   -0.288721   -0.425354  -0.472939 -0.390700 -0.361668 -0.473861  \n",
       "3    0.394289    0.838871    0.189852   2.745749  0.127628  0.260724  0.375190  \n",
       "4   -0.485963   -0.277843   -0.437998  -0.331662 -0.311161 -0.313198 -0.399826  \n",
       "5   -0.515366   -0.254830   -0.469172  -0.464866 -0.379008  0.226988 -0.368097  \n",
       "..        ...         ...         ...        ...       ...       ...       ...  \n",
       "79  -0.495381   -0.098557   -0.090718  -0.076557 -0.340390 -0.296950 -0.359577  \n",
       "80  -0.512609   -0.288721   -0.456528  -0.468095 -0.405757 -0.357675 -0.472098  \n",
       "81   0.433340   -0.288721    0.095893   0.201960 -0.361471 -0.361668 -0.459465  \n",
       "82  -0.267738   -0.263408   -0.470698  -0.442666  1.291473 -0.306451 -0.455058  \n",
       "83  -0.515366   -0.274077   -0.463940  -0.354267 -0.329407 -0.309205 -0.473861  \n",
       "\n",
       "[83 rows x 162 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing some Exploratory Data Analysis & checking correlation between the features columns and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>TCR a/b</th>\n",
       "      <th>TCR g/d</th>\n",
       "      <th>1a</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>mIgG1 50</th>\n",
       "      <th>mIgG 2a500</th>\n",
       "      <th>mIgG 2a200</th>\n",
       "      <th>mIgG 2a50</th>\n",
       "      <th>mIgG 2b500</th>\n",
       "      <th>mIgG 2b200</th>\n",
       "      <th>mIgG3 500</th>\n",
       "      <th>mIgM 500</th>\n",
       "      <th>mIgM 200</th>\n",
       "      <th>mIgM 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>83.000000</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.493976</td>\n",
       "      <td>-3.477807e-17</td>\n",
       "      <td>-6.153043e-17</td>\n",
       "      <td>4.079735e-17</td>\n",
       "      <td>-1.367715e-16</td>\n",
       "      <td>-2.875879e-16</td>\n",
       "      <td>-3.745331e-17</td>\n",
       "      <td>5.918960e-17</td>\n",
       "      <td>-2.467905e-16</td>\n",
       "      <td>1.585077e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>6.754971e-17</td>\n",
       "      <td>8.426994e-17</td>\n",
       "      <td>-2.407713e-17</td>\n",
       "      <td>7.624423e-17</td>\n",
       "      <td>6.086162e-17</td>\n",
       "      <td>-1.003214e-17</td>\n",
       "      <td>-9.363327e-18</td>\n",
       "      <td>6.286805e-17</td>\n",
       "      <td>-1.872665e-17</td>\n",
       "      <td>6.086162e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.108432</td>\n",
       "      <td>1.006079e+00</td>\n",
       "      <td>1.006079e+00</td>\n",
       "      <td>1.006079e+00</td>\n",
       "      <td>1.006079e+00</td>\n",
       "      <td>1.006079e+00</td>\n",
       "      <td>1.006079e+00</td>\n",
       "      <td>1.006079e+00</td>\n",
       "      <td>1.006079e+00</td>\n",
       "      <td>1.006079e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006079e+00</td>\n",
       "      <td>1.006079e+00</td>\n",
       "      <td>1.006079e+00</td>\n",
       "      <td>1.006079e+00</td>\n",
       "      <td>1.006079e+00</td>\n",
       "      <td>1.006079e+00</td>\n",
       "      <td>1.006079e+00</td>\n",
       "      <td>1.006079e+00</td>\n",
       "      <td>1.006079e+00</td>\n",
       "      <td>1.006079e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.204058e+00</td>\n",
       "      <td>-4.527841e-01</td>\n",
       "      <td>-5.601337e-01</td>\n",
       "      <td>-2.036077e+00</td>\n",
       "      <td>-1.738015e+00</td>\n",
       "      <td>-1.889704e+00</td>\n",
       "      <td>-1.872637e+00</td>\n",
       "      <td>-1.998690e+00</td>\n",
       "      <td>-1.386968e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.430889e-01</td>\n",
       "      <td>-4.140293e-01</td>\n",
       "      <td>-5.530661e-01</td>\n",
       "      <td>-5.153656e-01</td>\n",
       "      <td>-2.887210e-01</td>\n",
       "      <td>-4.720064e-01</td>\n",
       "      <td>-4.729392e-01</td>\n",
       "      <td>-4.082370e-01</td>\n",
       "      <td>-3.616677e-01</td>\n",
       "      <td>-4.738607e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.269758e-01</td>\n",
       "      <td>-4.194204e-01</td>\n",
       "      <td>-4.964822e-01</td>\n",
       "      <td>-6.662525e-01</td>\n",
       "      <td>-8.053006e-01</td>\n",
       "      <td>-7.241579e-01</td>\n",
       "      <td>-8.586634e-01</td>\n",
       "      <td>-6.383592e-01</td>\n",
       "      <td>-7.389088e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.230930e-01</td>\n",
       "      <td>-4.029779e-01</td>\n",
       "      <td>-5.369986e-01</td>\n",
       "      <td>-5.121497e-01</td>\n",
       "      <td>-2.810852e-01</td>\n",
       "      <td>-4.612152e-01</td>\n",
       "      <td>-4.392346e-01</td>\n",
       "      <td>-3.907881e-01</td>\n",
       "      <td>-3.496881e-01</td>\n",
       "      <td>-4.619622e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>-2.199834e-01</td>\n",
       "      <td>-3.346787e-01</td>\n",
       "      <td>-3.537133e-01</td>\n",
       "      <td>8.901931e-02</td>\n",
       "      <td>-2.385019e-01</td>\n",
       "      <td>-4.345654e-02</td>\n",
       "      <td>-7.024690e-02</td>\n",
       "      <td>1.827637e-02</td>\n",
       "      <td>-2.607751e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.683755e-01</td>\n",
       "      <td>-3.355646e-01</td>\n",
       "      <td>-3.923916e-01</td>\n",
       "      <td>-4.439256e-01</td>\n",
       "      <td>-2.562949e-01</td>\n",
       "      <td>-3.828430e-01</td>\n",
       "      <td>-3.712199e-01</td>\n",
       "      <td>-3.379102e-01</td>\n",
       "      <td>-2.710629e-01</td>\n",
       "      <td>-3.874867e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.647987e-01</td>\n",
       "      <td>4.980991e-03</td>\n",
       "      <td>-5.260459e-03</td>\n",
       "      <td>7.875038e-01</td>\n",
       "      <td>7.973472e-01</td>\n",
       "      <td>8.889802e-01</td>\n",
       "      <td>7.968390e-01</td>\n",
       "      <td>6.924136e-01</td>\n",
       "      <td>5.084345e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.867743e-02</td>\n",
       "      <td>-1.981760e-01</td>\n",
       "      <td>-5.312238e-03</td>\n",
       "      <td>1.618492e-02</td>\n",
       "      <td>-1.441633e-01</td>\n",
       "      <td>1.302282e-01</td>\n",
       "      <td>-1.909911e-01</td>\n",
       "      <td>-1.183385e-01</td>\n",
       "      <td>-5.205538e-02</td>\n",
       "      <td>-2.215985e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.567213e+00</td>\n",
       "      <td>6.670849e+00</td>\n",
       "      <td>6.215338e+00</td>\n",
       "      <td>1.809676e+00</td>\n",
       "      <td>2.048383e+00</td>\n",
       "      <td>1.882375e+00</td>\n",
       "      <td>1.922328e+00</td>\n",
       "      <td>1.843632e+00</td>\n",
       "      <td>2.891236e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.232866e+00</td>\n",
       "      <td>5.945531e+00</td>\n",
       "      <td>4.903605e+00</td>\n",
       "      <td>4.584212e+00</td>\n",
       "      <td>8.539551e+00</td>\n",
       "      <td>6.133499e+00</td>\n",
       "      <td>4.613025e+00</td>\n",
       "      <td>6.305575e+00</td>\n",
       "      <td>6.839900e+00</td>\n",
       "      <td>6.283290e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           label       TCR a/b       TCR g/d            1a             2  \\\n",
       "count  83.000000  8.300000e+01  8.300000e+01  8.300000e+01  8.300000e+01   \n",
       "mean    1.493976 -3.477807e-17 -6.153043e-17  4.079735e-17 -1.367715e-16   \n",
       "std     1.108432  1.006079e+00  1.006079e+00  1.006079e+00  1.006079e+00   \n",
       "min     0.000000 -1.204058e+00 -4.527841e-01 -5.601337e-01 -2.036077e+00   \n",
       "25%     0.000000 -8.269758e-01 -4.194204e-01 -4.964822e-01 -6.662525e-01   \n",
       "50%     2.000000 -2.199834e-01 -3.346787e-01 -3.537133e-01  8.901931e-02   \n",
       "75%     2.000000  6.647987e-01  4.980991e-03 -5.260459e-03  7.875038e-01   \n",
       "max     3.000000  2.567213e+00  6.670849e+00  6.215338e+00  1.809676e+00   \n",
       "\n",
       "                  3             4             5             7             8  \\\n",
       "count  8.300000e+01  8.300000e+01  8.300000e+01  8.300000e+01  8.300000e+01   \n",
       "mean  -2.875879e-16 -3.745331e-17  5.918960e-17 -2.467905e-16  1.585077e-16   \n",
       "std    1.006079e+00  1.006079e+00  1.006079e+00  1.006079e+00  1.006079e+00   \n",
       "min   -1.738015e+00 -1.889704e+00 -1.872637e+00 -1.998690e+00 -1.386968e+00   \n",
       "25%   -8.053006e-01 -7.241579e-01 -8.586634e-01 -6.383592e-01 -7.389088e-01   \n",
       "50%   -2.385019e-01 -4.345654e-02 -7.024690e-02  1.827637e-02 -2.607751e-01   \n",
       "75%    7.973472e-01  8.889802e-01  7.968390e-01  6.924136e-01  5.084345e-01   \n",
       "max    2.048383e+00  1.882375e+00  1.922328e+00  1.843632e+00  2.891236e+00   \n",
       "\n",
       "       ...      mIgG1 50    mIgG 2a500    mIgG 2a200     mIgG 2a50  \\\n",
       "count  ...  8.300000e+01  8.300000e+01  8.300000e+01  8.300000e+01   \n",
       "mean   ...  6.754971e-17  8.426994e-17 -2.407713e-17  7.624423e-17   \n",
       "std    ...  1.006079e+00  1.006079e+00  1.006079e+00  1.006079e+00   \n",
       "min    ... -4.430889e-01 -4.140293e-01 -5.530661e-01 -5.153656e-01   \n",
       "25%    ... -4.230930e-01 -4.029779e-01 -5.369986e-01 -5.121497e-01   \n",
       "50%    ... -3.683755e-01 -3.355646e-01 -3.923916e-01 -4.439256e-01   \n",
       "75%    ...  1.867743e-02 -1.981760e-01 -5.312238e-03  1.618492e-02   \n",
       "max    ...  7.232866e+00  5.945531e+00  4.903605e+00  4.584212e+00   \n",
       "\n",
       "         mIgG 2b500    mIgG 2b200     mIgG3 500      mIgM 500      mIgM 200  \\\n",
       "count  8.300000e+01  8.300000e+01  8.300000e+01  8.300000e+01  8.300000e+01   \n",
       "mean   6.086162e-17 -1.003214e-17 -9.363327e-18  6.286805e-17 -1.872665e-17   \n",
       "std    1.006079e+00  1.006079e+00  1.006079e+00  1.006079e+00  1.006079e+00   \n",
       "min   -2.887210e-01 -4.720064e-01 -4.729392e-01 -4.082370e-01 -3.616677e-01   \n",
       "25%   -2.810852e-01 -4.612152e-01 -4.392346e-01 -3.907881e-01 -3.496881e-01   \n",
       "50%   -2.562949e-01 -3.828430e-01 -3.712199e-01 -3.379102e-01 -2.710629e-01   \n",
       "75%   -1.441633e-01  1.302282e-01 -1.909911e-01 -1.183385e-01 -5.205538e-02   \n",
       "max    8.539551e+00  6.133499e+00  4.613025e+00  6.305575e+00  6.839900e+00   \n",
       "\n",
       "            mIgM 50  \n",
       "count  8.300000e+01  \n",
       "mean   6.086162e-17  \n",
       "std    1.006079e+00  \n",
       "min   -4.738607e-01  \n",
       "25%   -4.619622e-01  \n",
       "50%   -3.874867e-01  \n",
       "75%   -2.215985e-02  \n",
       "max    6.283290e+00  \n",
       "\n",
       "[8 rows x 161 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_average.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15         0.274982\n",
       "66c        0.185185\n",
       "36         0.167975\n",
       "41         0.167474\n",
       "10 ALB1    0.161388\n",
       "             ...   \n",
       "122       -0.348709\n",
       "2         -0.364057\n",
       "5         -0.371084\n",
       "56        -0.383415\n",
       "7         -0.385609\n",
       "Length: 160, dtype: float64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Correlation between features and label\n",
    "df_average[feature_cols].corrwith(df_average.label).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into training and testing sets, 80% training and 20% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X = df_average[feature_cols]\n",
    "y = df_average.label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 80% training and 20% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating four distinct classifier models: KNN (K-Nearest Neighbors classifier), Random Forest, Logistic Regression, and Decision Tree classifier. The scores for each model are stored in a list, which will serve as weights for a Voting Classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [] # List to store the weights of each classifier\n",
    "\n",
    "# Creating the classifiers, fitting them to the training data, predicting the test data and calculating the accuracy score. Then appending the accuracy score to the weights list.\n",
    "knn = KNeighborsClassifier(n_neighbors=7, weights='distance')\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "weights.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "weights.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "weights.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42, max_depth=1000)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "weights.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a voting classifier model using four different models: K-Nearest Neighbors (KNN), Random Forest, Logistic Regression, and Decision Tree. Each model is assigned a specific weight based on its accuracy. We use a \"hard\" voting scheme, which means that it selects the class label that receives the majority of votes from the individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model, we will be using a voting classifier from the 4 different models, while using there accuracy as weights.\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "lr = LogisticRegression()\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('knn', knn), ('rf', rf), ('lr', lr), ('dt', dt)], voting='hard', weights=weights)\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Voting Classifier: 0.6470588235294118\n"
     ]
    }
   ],
   "source": [
    "# Printing the accuracy of the Voting Classifier model\n",
    "print(\"Accuracy of Voting Classifier: \" + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo8AAAHFCAYAAACTuxPsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABNDklEQVR4nO3dfXxMZ/7/8fcIJmEiCBI3kdDUvajUTUPdtSEtq6hSKy3ZYNmt3lDaRhdpow2lVbRFbZuouutSVrvaLirKuilxs6pu4/42aLFSHSHn94ef+Zom4UTHjElez32cx6NznXOu85k5e8Ynn+tcZyyGYRgCAAAATCjm6QAAAADgPUgeAQAAYBrJIwAAAEwjeQQAAIBpJI8AAAAwjeQRAAAAppE8AgAAwDSSRwAAAJhG8ggAAADTSB4BAABgGskjAABAEREWFiaLxZJreeaZZ0z3UfwOxgcAAIC7yMaNG3X16lXH6x9++EHt27dXjx49TPdhMQzDuBPBAQAA4O72wgsv6Msvv9TevXtlsVhM7UPlEQAAwIvZ7XbZ7XanNqvVKqvVetP9Ll++rE8//VRDhw41nThKJI9woSFhvTwdAgpgyvHVng4BBRRZIdzTIaAANp/Z5+kQUEBXLh9z27Gyz+x3WV/J732i1157zalt9OjRSkxMvOl+ixcv1rlz5xQXF1eg4zFsDZchefQuJI/eh+TRu5A8eh+3Jo+Ze13WV05A9duqPMbExKhkyZL64osvCnQ8Ko8AAABezEyi+FuHDh3S8uXL9fnnnxf4eCSPAAAA7mbkePTwKSkpqlSpkjp16lTgfUkeAQAA3C3Hc8ljTk6OUlJS1LdvXxUvXvBUkIeEAwAAFCHLly/X4cOHFR8ff1v7U3kEAABwM8ODw9YdOnTQ75kvTfIIAADgbh4ctv69GLYGAACAaVQeAQAA3M3Ds61/D5JHAAAAd8u56ukIbhvD1gAAADCNyiMAAIC7MWwNAAAA05htDQAAgKKAyiMAAICbefIh4b8XySMAAIC7MWwNAACAooDKIwAAgLsxbA0AAADTeEg4AAAAigIqjwAAAO7GsDUAAABMY7Y1AAAAigIqjwAAAO7GsDUAAABMY9gaAAAARQGVRwAAADczDO99ziPJIwAAgLt58T2PDFsDAADANCqPAAAA7ubFE2ZIHgEAANyNYWsAAAAUBVQeAQAA3C2H2dYAAAAwi2FrAAAAFAVUHgEAANyN2dYAAAAwjWFrAAAAFAVUHgEAANyNYWsAAACY5sXJI8PWAAAAMI3kEbmkpaXJYrHo3Llzng4FAIBCyTCuumxxN5LHOywuLk4Wi0Vjx451al+8eLEsFouHosKtPPzXLhryzzeU/EOKXt80XfEfvqiKNSt7OizcwqCBfbV39zpdvJChDeu/0oMtm3k6JOSjcfMIvT0zWf/avFDfH1+lNo886OmQYALXmAvl5LhucTOSRzfw9fXVuHHj9PPPP7usz8uXL7usL+R2T/O6WjPr35rUbaSmPf2Givn4aNAnI1TSz+rp0JCPHj0e0ztvJyp57GQ1aRajNWu+15dffKqQkCqeDg158C3lp7079mn8q+96OhSYxDWG60ge3SA6OlrBwcFKTk7Od5uFCxeqfv36slqtCgsL09tvv+20PiwsTGPGjFFcXJwCAgI0YMAApaamqmzZsvryyy9Vu3ZtlSpVSk888YSysrI0c+ZMhYWFqVy5cnr22Wd19er/lbU//fRTNWnSRP7+/goODlbv3r2VmZl5x96/N/qw71htXLBKJ/ce1fGdhzV3+FSVr1ZR1RrW8HRoyMeQ5wfo45R5+jhlrnbt2qcXh43WkaPHNWhgH0+HhjysW7lB0976SGlfrfZ0KDCJa8zFjBzXLW5G8ugGPj4+evPNNzVlyhQdPXo01/r09HT17NlTvXr10vbt25WYmKiRI0cqNTXVabvx48erQYMGSk9P18iRIyVJv/zyiyZPnqx58+bp66+/Vlpamh5//HEtXbpUS5cu1axZs/Thhx9qwYIFjn4uX76spKQkbdu2TYsXL9aBAwcUFxd3Jz8Cr+fnX0qS9Mu5ix6OBHkpUaKEIiMjtGz5Kqf2ZctWKeqBJh6KCig8uMbuAC8etuZRPW7SrVs33XfffRo9erQ++ugjp3XvvPOOHn74YUdCWKtWLf34448aP368U1L30EMPadiwYY7Xa9asUXZ2tqZOnap77rlHkvTEE09o1qxZOnXqlGw2m+rVq6d27dpp5cqVevLJJyVJ8fHxjj5q1qypyZMnq1mzZrp48aJsNpup92O322W3253arhhXVdziY/5D8SJd/va09n+/Syf35E7+4XkVKpRX8eLFlXnqjFN7ZuYZBQVX8lBUQOHBNYYbUXl0o3HjxmnmzJn68ccfndp37typli1bOrW1bNlSe/fudRpubtIk9193pUqVciSOkhQUFKSwsDCnJDAoKMhpWHrLli3q0qWLQkND5e/vr7Zt20qSDh8+bPq9JCcnKyAgwGnZeH6n6f29SffX/6QqdUP1yXOTPR0KbsEwDKfXFoslVxuA28c15kIMW8OM1q1bKyYmRiNGjHBqNwwj18zrvC7G0qVL52orUaKE02uLxZJnW87/L2tnZWWpQ4cOstls+vTTT7Vx40YtWrRIUsEm4SQkJOj8+fNOS9OAuqb39xaPJ8apfnQTvd/rdZ0/+ZOnw0E+zpz5SVeuXFFQcEWn9ooVA5V56rSHogIKD66xO8CLh61JHt1s7Nix+uKLL7R27VpHW7169bRmzRqn7dauXatatWrJx8e1w8C7du3SmTNnNHbsWLVq1Up16tS5rckyVqtVZcqUcVoK25D146/9SQ0faaYPeifpp6N8Od7NsrOztXnzfxX9cGun9ujo1lq3fpOHogIKD64x3Ijk0c0aNmyo2NhYTZkyxdH24osvasWKFUpKStKePXs0c+ZMvffee073N7pK9erVVbJkSU2ZMkX79+/XkiVLlJSU5PLjeLvuSfFq0u1Bffr8FNmzLsm/YoD8KwaohLXErXeGR0ycNEP94v+ouL5Pqk6dcL09PlHVQ6pq+oezPB0a8uBXyk/31g/XvfXDJUlVQirr3vrhCqrK/XN3K64xF/PgsPWxY8f01FNPKTAwUKVKldJ9992n9PR00/szYcYDkpKS9NlnnzleR0ZG6rPPPtOoUaOUlJSkypUr6/XXX78jM6ArVqyo1NRUjRgxQpMnT1ZkZKQmTJigxx57zOXH8mYPPt1BkjR4/min9jnDpmrjglV57QIP+8c/liiwfDn97dUhqly5kn7YsVudH3tahw8f83RoyEPdRrU1beEkx+shrw2WJH05/yu9PmRsfrvBg7jGXMxDv239888/q2XLlmrXrp2++uorVapUSRkZGSpbtqzpPiwGd7rCRYaE9fJ0CCiAKcd5vp63iawQ7ukQUACbz+zzdAgooCuX3ZcIX/rKdZMw/R59zvS2r7zyiv7zn/9o9erb/zeAYWsAAAB3c+GEGbvdrgsXLjgtv32c3nVLlixRkyZN1KNHD1WqVEmNGzfWjBkzChQ6ySMAAIC7ufCex7wen5ffr9rt379fU6dO1b333qtvvvlGgwYN0nPPPadPPvnEdOjc8wgAAODFEhISNHToUKc2q9Wa57Y5OTlq0qSJ3nzzTUlS48aNtWPHDk2dOlV9+vQxdTySRwAAAHdz4YQZq9Wab7L4W5UrV1a9evWc2urWrauFCxeaPh7JIwAAgLt54JdhpGu/YLd7926ntj179ig0NNR0H9zzCAAAUEQMGTJE69ev15tvvql9+/Zpzpw5+vDDD/XMM8+Y7oPKIwAAgLt56DmPTZs21aJFi5SQkKDXX39dNWrU0LvvvqvY2FjTfZA8AgAAuJuHhq0l6Q9/+IP+8Ic/3Pb+DFsDAADANCqPAAAA7uahYWtXIHkEAABwNy9OHhm2BgAAgGlUHgEAANzNMDwdwW0jeQQAAHA3hq0BAABQFFB5BAAAcDcvrjySPAIAALibBx8S/nsxbA0AAADTqDwCAAC4G8PWAAAAMM2LH9XDsDUAAABMo/IIAADgbgxbAwAAwDQvTh4ZtgYAAIBpVB4BAADczYuf80jyCAAA4GZGDrOtAQAAUARQeQQAAHA3L54wQ/IIAADgbl58zyPD1gAAADCNyiMAAIC7efGEGZJHAAAAd/Piex4ZtgYAAIBpVB4BAADczYsrjySPAAAA7mZ47z2PDFsDAADANCqPAAAA7sawNQAAAEzz4kf1MGwNAAAA06g8AgAAuJsX/zwhySMAAIC7MWwNAACAooDKI1zmP5dPeDoEFEBkhXBPh4AC2nxmn6dDAOAiBrOtAQAAYBrD1gAAACgKqDwCAAC4G7OtAQAAYBrD1gAAACgKqDwCAAC4G7OtAQAAYBrD1gAAACgKqDwCAAC4mxfPtqbyCAAA4G45huuWAkhMTJTFYnFagoODC9QHlUcAAIAipH79+lq+fLnjtY+PT4H2J3kEAABwM0/+tnXx4sULXG28EcPWAAAA7ubCYWu73a4LFy44LXa7Pd9D7927V1WqVFGNGjXUq1cv7d+/v0ChkzwCAAB4seTkZAUEBDgtycnJeW7bvHlzffLJJ/rmm280Y8YMnTx5Ui1atNDZs2dNH89iGIb3PmgId5VmVdp4OgSgUNt8Zp+nQwAKtSuXj7ntWBeHd3NZXyXGzMtVabRarbJarbfcNysrS/fcc49eeuklDR061NTxuOcRAADA3Vz4qB6ziWJeSpcurYYNG2rv3r2m92HYGgAAoIiy2+3auXOnKleubHofkkcAAAB389BzHocNG6ZVq1bpwIED2rBhg5544glduHBBffv2Nd0Hw9YAAABuZnjot62PHj2qP/7xjzpz5owqVqyoBx54QOvXr1doaKjpPkgeAQAAioh58+b97j5IHgEAANzNQ5VHVyB5BAAAcDcP/sLM78WEGQAAAJhG5REAAMDdGLYGAACAaV6cPDJsDQAAANOoPAIAALiZYXhv5ZHkEQAAwN0YtgYAAEBRQOURAADA3by48kjyCAAA4Gae+m1rV2DYGgAAAKZReQQAAHA3L648kjwCAAC4m/f+tDXD1gAAADCPyiMAAICbefOEGZJHAAAAd/Pi5JFhawAAAJhG5REAAMDdvHjCDMkjAACAm3nzPY8MWwMAAMA0ksdCqG3btnrhhRc8HQYAAMhPjgsXNyvyyWNmZqYGDhyo6tWry2q1Kjg4WDExMVq3bp0kKSwsTO+++26e+x48eFAWiyXPZf369Xc89rS0NFksFp07d86p/fPPP1dSUtIdP35h1rh5hN6emax/bV6o74+vUptHHvR0SLgFzpl3GjSwr/buXqeLFzK0Yf1XerBlM0+HhJvgfLmOkWO4bHG3Ip88du/eXdu2bdPMmTO1Z88eLVmyRG3bttVPP/1kuo/ly5frxIkTTsv9999/B6O+ufLly8vf399jxy8MfEv5ae+OfRr/6rueDgUmcc68T48ej+mdtxOVPHaymjSL0Zo13+vLLz5VSEgVT4eGPHC+cF2RTh7PnTunNWvWaNy4cWrXrp1CQ0PVrFkzJSQkqFOnTqb7CQwMVHBwsNNSokSJW+6XkZGhLl26KCgoSDabTU2bNtXy5cudtrHb7XrppZcUEhIiq9Wqe++9Vx999JEOHjyodu3aSZLKlSsni8WiuLg4Sc7D1gkJCXrggQdyHTsiIkKjR492vE5JSVHdunXl6+urOnXq6IMPPjD9/gujdSs3aNpbHyntq9WeDgUmcc68z5DnB+jjlHn6OGWudu3apxeHjdaRo8c1aGAfT4eGPHC+XIxha+9ks9lks9m0ePFi2e12tx//4sWL6tixo5YvX64tW7YoJiZGnTt31uHDhx3b9OnTR/PmzdPkyZO1c+dOTZs2TTabTSEhIVq4cKEkaffu3Tpx4oQmTZqU6xixsbHasGGDMjIyHG07duzQ9u3bFRsbK0maMWOGXn31Vb3xxhvauXOn3nzzTY0cOVIzZ868w58AgKKqRIkSioyM0LLlq5zaly1bpagHmngoKuSH8+V6Ro7rFncr0o/qKV68uFJTUzVgwABNmzZNkZGRatOmjXr16qWIiAjT/bRo0ULFijnn4efPn5ePj89N92vUqJEaNWrkeD1mzBgtWrRIS5Ys0eDBg7Vnzx599tlnWrZsmaKjoyVJNWvWdGxfvnx5SVKlSpVUtmzZPI/RoEEDRUREaM6cORo5cqQkafbs2WratKlq1aolSUpKStLbb7+txx9/XJJUo0YN/fjjj5o+fbr69u2bZ792uz1Xwp1j5KiYpUj/PQLApAoVyqt48eLKPHXGqT0z84yCgit5KCrkh/OFGxX5f+m7d++u48ePa8mSJYqJiVFaWpoiIyOVmppquo/58+dr69atTsutEkdJysrK0ksvvaR69eqpbNmystls2rVrl6PyeL2fNm3a3O7bk3St+jh79mxJkmEYmjt3rqPqePr0aR05ckT9+vVzVGJtNpvGjBnjVK38reTkZAUEBDgtJy4eznd7AMiLYTjf7G+xWHK14e7B+XIhLx62LtKVx+t8fX3Vvn17tW/fXqNGjVL//v01evRoxz2EtxISEqLw8PACH3f48OH65ptvNGHCBIWHh8vPz09PPPGELl++LEny8/MrcJ956d27t1555RVt3rxZly5d0pEjR9SrVy9JUk7Otf/XzZgxQ82bN3fa72YJcEJCgoYOHerU9lBt8/eJAijazpz5SVeuXFFQcEWn9ooVA5V56rSHokJ+OF+u54nhZlcp8pXHvNSrV09ZWVl3/DirV69WXFycunXrpoYNGyo4OFgHDx50rG/YsKFycnK0atWqPPcvWbKkJOnq1as3PU61atXUunVrzZ49W7Nnz1Z0dLSCgoIkSUFBQapatar279+v8PBwp6VGjRr59mm1WlWmTBmnhSFrAGZlZ2dr8+b/Kvrh1k7t0dGttW79Jg9FhfxwvnCjIl15PHv2rHr06KH4+HhFRETI399fmzZt0ltvvaUuXbo4tjt27Ji2bt3qtG/16tWd+jl58qTT+rJly8rX1/emxw8PD9fnn3+uzp07y2KxaOTIkY5KoHTtGZN9+/ZVfHy8Jk+erEaNGunQoUPKzMxUz549FRoaKovFoi+//FIdO3aUn5+fbDZbnseKjY1VYmKiLl++rIkTJzqtS0xM1HPPPacyZcro0Ucfld1u16ZNm/Tzzz/nqi4WFX6l/FStRlXH6yohlXVv/XBdOHdBp45lejAy5Idz5n0mTpqhmSmTlJ6+Tes3pGtAv6dUPaSqpn84y9OhIQ+cLxfz4sqjxSjCNyvY7XYlJibq3//+tzIyMpSdna2QkBD16NFDI0aMkJ+fn8LCwnTo0KFc+6akpKht27b5Vufmzp3rGBrOz8GDBxUfH6/169erQoUKevnll/WPf/xD9913n+PB5L/++qtGjBihefPm6ezZs6pevbpGjBihP/3pT5KuTXb54IMPdOrUKfXp00epqalq27atUx/StccSBQcHy8fHR6dOncqVZM6ZM0fjx4/Xjz/+qNKlS6thw4Z64YUX1K1bN9OfZ7Mqv+/ezLtJZNR9mrYw9+z1L+d/pdeHjPVARLiVonDONp/Z5+kQXG7QwL4a9uJfVLlyJf2wY7eGDUvU6jUbPB0W8lHYz9eVy8fcdqzT7V33b2bFZXmPUN4pRTp5hGsVpuQRuBsVxuQRuJuQPJpTpIetAQAAPIEJM8hT/fr1nR5/c+Ny/dE5AACg6OEh4cjT0qVLlZ2dnee667OdAQAAvAnJ4x0UGhrq6RAAAMDdyLB4OoLbRvIIAADgZtzzCAAAgCKByiMAAICbGTkMWwMAAMAkhq0BAABQJFB5BAAAcDOD2dYAAAAwi2FrAAAAeJ3k5GRZLBa98MILpveh8ggAAOBmd8Ns640bN+rDDz9UREREgfaj8ggAAFDEXLx4UbGxsZoxY4bKlStXoH1JHgEAANzMMFy32O12XbhwwWmx2+03Pf4zzzyjTp06KTo6usCxkzwCAAC4mZFjcdmSnJysgIAApyU5OTnfY8+bN0+bN2++6TY3wz2PAAAAXiwhIUFDhw51arNarXlue+TIET3//PP697//LV9f39s6HskjAACAm7lywozVas03Wfyt9PR0ZWZm6v7773e0Xb16Vd99953ee+892e12+fj43LQPkkcAAAA3MwzPHPfhhx/W9u3bndr+9Kc/qU6dOnr55ZdvmThKJI8AAABFhr+/vxo0aODUVrp0aQUGBuZqzw/JIwAAgJvdDc95vF0kjwAAAG52N/22dVpaWoG251E9AAAAMI3KIwAAgJsZOZ6O4PaZSh6XLFliusPHHnvstoMBAAAoCnLuomHrgjKVPHbt2tVUZxaLRVevXv098QAAAOAuZip5zMnx4toqAADAXeZumjBTUNzzCAAA4GZF7lE9WVlZWrVqlQ4fPqzLly87rXvuuedcEhgAAADuPgVOHrds2aKOHTvql19+UVZWlsqXL68zZ86oVKlSqlSpEskjAADALXjq5wldocDPeRwyZIg6d+6sn376SX5+flq/fr0OHTqk+++/XxMmTLgTMQIAABQqRo7FZYu7FTh53Lp1q1588UX5+PjIx8dHdrtdISEheuuttzRixIg7ESMAAADuEgVOHkuUKCGL5VqWGxQUpMOHD0uSAgICHP8NAACA/OUYFpct7lbgex4bN26sTZs2qVatWmrXrp1GjRqlM2fOaNasWWrYsOGdiBEAAKBQ8eZH9RS48vjmm2+qcuXKkqSkpCQFBgbqL3/5izIzM/Xhhx+6PEAAAADcPQpceWzSpInjvytWrKilS5e6NCAAAIDCzptnW/OQcAAAADcr9L9tfaMaNWo4JszkZf/+/b8rIAAAANy9Cpw8vvDCC06vs7OztWXLFn399dcaPny4q+ICAAAotLx5wkyBk8fnn38+z/b3339fmzZt+t0BAQAAFHbefM9jgWdb5+fRRx/VwoULXdUdAAAA7kIumzCzYMEClS9f3lXdAQAAFFpFasJM48aNnSbMGIahkydP6vTp0/rggw9cGhyAO2fzmX2eDgEFdOn4ak+HgALwq9LK0yHgLlak7nns0qWLU/JYrFgxVaxYUW3btlWdOnVcGhwAAADuLgVOHhMTE+9AGAAAAEWHNw9bF3jCjI+PjzIzM3O1nz17Vj4+Pi4JCgAAoDAzXLi4W4GTRyOfueV2u10lS5b83QEBAADg7mV62Hry5MmSJIvFor///e+y2WyOdVevXtV3333HPY8AAAAmePOwtenkceLEiZKuVR6nTZvmNERdsmRJhYWFadq0aa6PEAAAoJApErOtDxw4IElq166dPv/8c5UrV+6OBQUAAIC7U4FnW69cufJOxAEAAFBk5Hg6gN+hwBNmnnjiCY0dOzZX+/jx49WjRw+XBAUAAFCYGbK4bHG3AiePq1atUqdOnXK1P/LII/ruu+9cEhQAAADuTgUetr548WKej+QpUaKELly44JKgAAAACrMcTzyg0UUKXHls0KCB5s+fn6t93rx5qlevnkuCAgAAKMxyZHHZ4m4FrjyOHDlS3bt3V0ZGhh566CFJ0ooVKzRnzhwtWLDA5QECAADg7lHg5PGxxx7T4sWL9eabb2rBggXy8/NTo0aN9O2336pMmTJ3IkYAAIBCxRMTXVylwMmjJHXq1MkxaebcuXOaPXu2XnjhBW3btk1Xr151aYAAAACFTZF6VM913377rZ566ilVqVJF7733njp27KhNmza5MjYAAADcZQpUeTx69KhSU1P18ccfKysrSz179lR2drYWLlzIZBkAAACTvHnY2nTlsWPHjqpXr55+/PFHTZkyRcePH9eUKVPuZGwAAACFUo4LF3czXXn897//reeee05/+ctfdO+9997JmAAAAHCXMl15XL16tf73v/+pSZMmat68ud577z2dPn36TsYGAABQKHlz5dF08hgVFaUZM2boxIkTGjhwoObNm6eqVasqJydHy5Yt0//+9787GScAAEChUaR+27pUqVKKj4/XmjVrtH37dr344osaO3asKlWqpMcee+xOxAgAAIC7xG0/qkeSateurbfeektHjx7V3LlzXRUTAABAoZZjcd3ibr8rebzOx8dHXbt21ZIlS1zRHQAAQKHmqd+2njp1qiIiIlSmTBmVKVNGUVFR+uqrrwrUh0uSRwAAANz9qlWrprFjx2rTpk3atGmTHnroIXXp0kU7duww3cdt/TwhAAAAbp/hoeN27tzZ6fUbb7yhqVOnav369apfv76pPkgeAQAA3MyVj9ix2+2y2+1ObVarVVar9ab7Xb16Vf/4xz+UlZWlqKgo08dj2BoAAMCLJScnKyAgwGlJTk7Od/vt27fLZrPJarVq0KBBWrRoUYF+ZprKIwAAgJvlWFw3TTohIUFDhw51artZ1bF27draunWrzp07p4ULF6pv375atWqV6QSS5BEAAMDNXHnPo5kh6huVLFlS4eHhkqQmTZpo48aNmjRpkqZPn25qf4atAQAAijDDMHLdM3kzVB4BAADczBO/SS1JI0aM0KOPPqqQkBD973//07x585SWlqavv/7adB8kjwAAAG7miV+GkaRTp07p6aef1okTJxQQEKCIiAh9/fXXat++vek+SB4BAACKiI8++uh390HyCAAA4GYF/VnBuwnJIwAAgJt56hdmXIHZ1gAAADCNyiMAAICbeWrCjCuQPAIAALiZpx7V4woMWwMAAMA0Ko8AAABuxoQZSJISExN13333eToMHTx4UBaLRVu3bvV0KAAAIA85Ftct7lboksfMzEwNHDhQ1atXl9VqVXBwsGJiYrRu3TpJUlhYmN599908972edOW1rF+//pbHHjZsmFasWOHKt3NLcXFx6tq1q1NbSEiITpw4oQYNGrg1lsKkcfMIvT0zWf/avFDfH1+lNo886OmQYMKggX21d/c6XbyQoQ3rv9KDLZt5OiTko0P3vmrQ8tFcy5i33/d0aLgJrjFIhXDYunv37srOztbMmTNVs2ZNnTp1SitWrNBPP/1kuo/ly5erfv36Tm2BgYG33M9ms8lmsxU4Zlfz8fFRcHCwp8Pwar6l/LR3xz59MW+p3vpojKfDgQk9ejymd95O1OBnR2jtuo0a0P9pffnFp2rYqK2OHDnu6fDwG/P+Pkk5Of83ZWDv/kMa8MIIdWjXyoNR4Wa4xlyLCTN3iXPnzmnNmjUaN26c2rVrp9DQUDVr1kwJCQnq1KmT6X4CAwMVHBzstJQoUeKW+/122Pp6VXDChAmqXLmyAgMD9cwzzyg7O9uxzaeffqomTZrI399fwcHB6t27tzIzM5363bFjhzp16qQyZcrI399frVq1UkZGhhITEzVz5kz985//dFRI09LSnIatc3JyVK1aNU2bNs2pz82bN8tisWj//v2SpPPnz+vPf/6zKlWqpDJlyuihhx7Stm3bTH9mhc26lRs07a2PlPbVak+HApOGPD9AH6fM08cpc7Vr1z69OGy0jhw9rkED+3g6NOShfLmyqhBY3rGs+s8GhVStrKaNG3o6NOSDa8y1cly4uFuhSh6vV/4WL14su93u6XAkSStXrlRGRoZWrlypmTNnKjU1VampqY71ly9fVlJSkrZt26bFixfrwIEDiouLc6w/duyYWrduLV9fX3377bdKT09XfHy8rly5omHDhqlnz5565JFHdOLECZ04cUItWrRwOn6xYsXUq1cvzZ4926l9zpw5ioqKUs2aNWUYhjp16qSTJ09q6dKlSk9PV2RkpB5++OECVWwBTylRooQiIyO0bPkqp/Zly1Yp6oEmHooKZmVnZ+vLf69Ut04dZLF48cPvCjGuMdyoUA1bFy9eXKmpqRowYICmTZumyMhItWnTRr169VJERITpflq0aKFixZzz6vPnz8vHx6fAMZUrV07vvfeefHx8VKdOHXXq1EkrVqzQgAEDJEnx8fGObWvWrKnJkyerWbNmunjxomw2m95//30FBARo3rx5jupnrVq1HPv4+fnJbrffdJg6NjZW77zzjg4dOqTQ0FDl5ORo3rx5GjFihKRrCe727duVmZkpq9UqSZowYYIWL16sBQsW6M9//nOuPu12e64EPcfIUTFLofp7BF6iQoXyKl68uDJPnXFqz8w8o6DgSh6KCmat+G6d/nfxorp2bO/pUJAPrjHXM7z476RC9y999+7ddfz4cS1ZskQxMTFKS0tTZGSkU7XvVubPn6+tW7c6LbeTOEpS/fr1nfatXLmy07D0li1b1KVLF4WGhsrf319t27aVJB0+fFiStHXrVrVq1crUsHl+GjdurDp16mju3LmSpFWrVikzM1M9e/aUJKWnp+vixYsKDAx0VG9tNpsOHDigjIyMPPtMTk5WQECA03Li4uHbjhFwBcNwfviFxWLJ1Ya7z+dffqMHH2iiShVvfW85PItrzHUYtr7L+Pr6qn379ho1apTWrl2ruLg4jR492vT+ISEhCg8Pd1pu12+TPovF4rhJPCsrSx06dJDNZtOnn36qjRs3atGiRZKuDWdL1yqLrhAbG6s5c+ZIujZkHRMTowoVKkiScnJyVLly5VwJ8+7duzV8+PA8+0tISND58+edlsq26i6JFSioM2d+0pUrVxQUXNGpvWLFQGWeOu2hqGDG8ZOntH7TVnXv/IinQ8FNcI3hRoUyefytevXqKSsry9Nh5LJr1y6dOXNGY8eOVatWrVSnTp1ck2UiIiK0evVqp0k2NypZsqSuXr16y2P17t1b27dvV3p6uhYsWKDY2FjHusjISJ08eVLFixfPlTRfTzB/y2q1qkyZMk4LQ9bwlOzsbG3e/F9FP9zaqT06urXWrd/koahgxqJ/LVP5cgFqHcUjX+5mXGOu582Vx0J1z+PZs2fVo0cPxcfHKyIiQv7+/tq0aZPeeustdenSxbHdsWPHcj1Au3r16k79nDx50ml92bJl5evr69J4q1evrpIlS2rKlCkaNGiQfvjhByUlJTltM3jwYE2ZMkW9evVSQkKCAgICtH79ejVr1ky1a9dWWFiYvvnmG+3evVuBgYEKCAjI81g1atRQixYt1K9fP125csXp84iOjlZUVJS6du2qcePGqXbt2jp+/LiWLl2qrl27qkmToncztF8pP1WrUdXxukpIZd1bP1wXzl3QqWOZN9kTnjJx0gzNTJmk9PRtWr8hXQP6PaXqIVU1/cNZng4N+cjJydHify1Tl0ejVbz47d0aBPfhGnMtbx7sL1TJo81mU/PmzTVx4kRlZGQoOztbISEhGjBggGNyiHRtMsiECROc9k1JSXHcbxgdHZ2r77lz56pXr14ujbdixYpKTU3ViBEjNHnyZEVGRmrChAl67LHHHNsEBgbq22+/1fDhw9WmTRv5+PjovvvuU8uWLSVJAwYMUFpampo0aaKLFy9q5cqVCgsLy/N4sbGxeuaZZ9SnTx+n4XCLxaKlS5fq1VdfVXx8vE6fPq3g4GC1bt1aQUFBLn3P3qJuo9qatnCS4/WQ1wZLkr6c/5VeHzLWU2HhJv7xjyUKLF9Of3t1iCpXrqQfduxW58ee1uHDxzwdGvKxbuMWnTiVqW6dOng6FJjANYbrLAZ3usJFmlVp4+kQUACbz+zzdAgooEvHee6oN/GrwgPPvc2Vy+5LhCdVf8plfT1/+FOX9WVGoao8AgAAeAN+YaaIqF+/vtOjbG5cfvsQbgAAgMKIymMBLF26NN9Zz0X13kAAAFBw3lx5JHksgNDQUE+HAAAACgFvnnDCsDUAAABMo/IIAADgZjle/NvWJI8AAABu5s33PDJsDQAAANOoPAIAALiZN0+YIXkEAABwsxwvTh8ZtgYAAIBpVB4BAADczJsnzJA8AgAAuJn3DlozbA0AAIACoPIIAADgZgxbAwAAwDRv/oUZhq0BAABgGpVHAAAAN/Pm5zySPAIAALiZ96aODFsDAACgAKg8AgAAuBmzrQEAAGCaN9/zyLA1AAAATKPyCAAA4GbeW3ckeQQAAHA7b77nkWFrAACAIiI5OVlNmzaVv7+/KlWqpK5du2r37t0F6oPkEQAAwM1yZLhsKYhVq1bpmWee0fr167Vs2TJduXJFHTp0UFZWluk+GLYGAABwM0/d8/j11187vU5JSVGlSpWUnp6u1q1bm+qD5BEAAMCL2e122e12pzar1Sqr1XrLfc+fPy9JKl++vOnjMWwNAADgZjkuXJKTkxUQEOC0JCcn3zIGwzA0dOhQPfjgg2rQoIHp2Kk8AgAAuJnhwoHrhIQEDR061KnNTNVx8ODB+u9//6s1a9YU6HgkjwAAAF7M7BD1jZ599lktWbJE3333napVq1agfUkeAQAA3MxTz3k0DEPPPvusFi1apLS0NNWoUaPAfZA8AgAAuJmnftv6mWee0Zw5c/TPf/5T/v7+OnnypCQpICBAfn5+pvpgwgwAAEARMXXqVJ0/f15t27ZV5cqVHcv8+fNN90HlEQAAwM089ZxHw/j9RyZ5BAAAcDNPDVu7AsPWAAAAMI3KIwAAgJt5ara1K5A8AgAAuJkrHxLubgxbAwAAwDQqjwAAAG7GsDUA4I57qckIT4eAAoisEO7pEHAXY9gaAAAARQKVRwAAADdj2BoAAACm5bjgl148hWFrAAAAmEblEQAAwM28t+5I8ggAAOB2/LY1AAAAigQqjwAAAG7mzc95JHkEAABwM29+VA/D1gAAADCNyiMAAICbefOEGZJHAAAAN/Pmex4ZtgYAAIBpVB4BAADczJsnzJA8AgAAuJnBb1sDAACgKKDyCAAA4GbMtgYAAIBp3nzPI8PWAAAAMI3KIwAAgJt583MeSR4BAADczJvveWTYGgAAAKZReQQAAHAzb37OI8kjAACAmzHbGgAAAEUClUcAAAA3Y7Y1AAAATGO2NQAAAIoEKo8AAABuxmxrAAAAmMawNQAAAIoEKo8AAABuxmxrAAAAmJbjxfc8MmwNAAAA06g8AgAAuJn31h1JHgEAANyO2dYAAAAoEkgeAQAA3CxHhsuWgvruu+/UuXNnValSRRaLRYsXLy7Q/iSPAAAAbmYYhsuWgsrKylKjRo303nvv3Vbs3PMIAABQhDz66KN69NFHb3t/kkcAAAA3c+WEGbvdLrvd7tRmtVpltVpddowbMWztRqmpqSpbtuwdP07btm31wgsv3PHjAACA22O48H/JyckKCAhwWpKTk+9Y7B5NHjMzMzVw4EBVr15dVqtVwcHBiomJ0bp16yRJYWFhevfdd/Pc9+DBg7JYLHku69evd+O7MO/JJ5/Unj17XNZfWlqaLBaLzp0759T++eefKykpyWXHKYoaN4/Q2zOT9a/NC/X98VVq88iDng4JJgwa2Fd7d6/TxQsZ2rD+Kz3YspmnQ0I+Hv5rFw355xtK/iFFr2+arvgPX1TFmpU9HRZugu/Fu1dCQoLOnz/vtCQkJNyx43l02Lp79+7Kzs7WzJkzVbNmTZ06dUorVqzQTz/9ZLqP5cuXq379+k5tgYGBrg7VJfz8/OTn53fHj1O+fPk7fozCzreUn/bu2Kcv5i3VWx+N8XQ4MKFHj8f0ztuJGvzsCK1dt1ED+j+tL7/4VA0btdWRI8c9HR5+457mdbVm1r91ZFuGihUvpo7DemnQJyM0rv0wXb5kv3UHcDu+F13rdia65OdODlHnxWOVx3PnzmnNmjUaN26c2rVrp9DQUDVr1kwJCQnq1KmT6X4CAwMVHBzstJQoUeKW+23btk3t2rWTv7+/ypQpo/vvv1+bNm1yrF+7dq1at24tPz8/hYSE6LnnnlNWVpZjfVhYmMaMGaM+ffrIZrMpNDRU//znP3X69Gl16dJFNptNDRs2dOrzt8PWGRkZ6tKli4KCgmSz2dS0aVMtX77cKU673a6XXnpJISEhslqtuvfee/XRRx/p4MGDateunSSpXLlyslgsiouLk+Q8bJ2QkKAHHngg1/uPiIjQ6NGjHa9TUlJUt25d+fr6qk6dOvrggw9u+RkWZutWbtC0tz5S2lerPR0KTBry/AB9nDJPH6fM1a5d+/TisNE6cvS4Bg3s4+nQkIcP+47VxgWrdHLvUR3feVhzh09V+WoVVa1hDU+HhnzwvehannxUz+/lseTRZrPJZrNp8eLFuW7ydIfY2FhVq1ZNGzduVHp6ul555RVH0rl9+3bFxMTo8ccf13//+1/Nnz9fa9as0eDBg536mDhxolq2bKktW7aoU6dOevrpp9WnTx899dRT2rx5s8LDw9WnT598/7q4ePGiOnbsqOXLl2vLli2KiYlR586ddfjwYcc2ffr00bx58zR58mTt3LlT06ZNk81mU0hIiBYuXChJ2r17t06cOKFJkybl+T43bNigjIwMR9uOHTu0fft2xcbGSpJmzJihV199VW+88YZ27typN998UyNHjtTMmTN/34cMuEmJEiUUGRmhZctXObUvW7ZKUQ808VBUKAg//1KSpF/OXfRwJEDhd/HiRW3dulVbt26VJB04cEBbt251yj9uxmPD1sWLF1dqaqoGDBigadOmKTIyUm3atFGvXr0UERFhup8WLVqoWDHnHPj8+fPy8fG56X6HDx/W8OHDVadOHUnSvffe61g3fvx49e7d21G9u/feezV58mS1adNGU6dOla+vrySpY8eOGjhwoCRp1KhRmjp1qpo2baoePXpIkl5++WVFRUXp1KlTCg4OzhVDo0aN1KhRI8frMWPGaNGiRVqyZIkGDx6sPXv26LPPPtOyZcsUHR0tSapZs6Zj++vD05UqVcp3Ik6DBg0UERGhOXPmaOTIkZKk2bNnq2nTpqpVq5YkKSkpSW+//bYef/xxSVKNGjX0448/avr06erbt2+e/eY1syvHyFExC3Ow4H4VKpRX8eLFlXnqjFN7ZuYZBQVX8lBUKIguf3ta+7/fpZN7jno6FMAtXDlsXVCbNm1yjF5K0tChQyVJffv2VWpq6i339+i/9N27d9fx48e1ZMkSxcTEKC0tTZGRkaYCv27+/PmO7Pn6cqvEUbr2QfXv31/R0dEaO3asU2UuPT1dqampjuqozWZTTEyMcnJydODAAcd2Nya5QUFBkqSGDRvmasvMzMwzhqysLL300kuqV6+eypYtK5vNpl27djky/+vvpU2bNqY/j7zExsZq9uzZkq79n3Xu3LmOquPp06d15MgR9evXz+n9jhkzxukz+a28ZnaduGjuLxbgTvntl7HFYvHoFzTM6f76n1Slbqg+eW6yp0MB3MaTw9Zt27bN82HjZvMvj5eJfH191b59e40aNUpr165VXFyc0714txISEqLw8HCnxYzExETt2LFDnTp10rfffqt69epp0aJFkqScnBwNHDjQKSHdtm2b9u7dq3vuucfRx433VloslnzbcnJy8oxh+PDhWrhwod544w2tXr1aW7duVcOGDXX58mVJctnkmt69e2vPnj3avHmz1q5dqyNHjqhXr15Osc2YMcPp/f7www83nbWe18yuyrbqLokXKKgzZ37SlStXFBRc0am9YsVAZZ467aGoYMbjiXGqH91E7/d6XedPmp8sCcBz7rqHhNerV6/Av7F4u2rVqqVatWppyJAh+uMf/6iUlBR169ZNkZGR2rFjh+lE9HatXr1acXFx6tatm6Rr9yAcPHjQsb5hw4bKycnRqlWrHMPWNypZsqQk6erVqzc9TrVq1dS6dWvNnj1bly5dUnR0tKMqGhQUpKpVq2r//v2OaqQZec3sYsganpKdna3Nm/+r6Idb65///NrRHh3dWl988Y0HI8PNPP7an9Qwpqne7/W6fjpKko+ixfDARBdX8VjyePbsWfXo0UPx8fGKiIiQv7+/Nm3apLfeektdunRxbHfs2DHHDZ3XVa9e3amfkydPOq0vW7as477EvFy6dEnDhw/XE088oRo1aujo0aPauHGjunfvLunavYoPPPCAnnnmGQ0YMEClS5fWzp07tWzZMk2ZMsUF7/6a8PBwff755+rcubMsFotGjhzpVKUMCwtT3759FR8fr8mTJ6tRo0Y6dOiQMjMz1bNnT4WGhspisejLL79Ux44d5efnJ5vNluexYmNjlZiYqMuXL2vixIlO6xITE/Xcc8+pTJkyevTRR2W327Vp0yb9/PPPjvsgihq/Un6qVqOq43WVkMq6t364Lpy7oFPH8r4NAZ41cdIMzUyZpPT0bVq/IV0D+j2l6iFVNf3DWZ4ODXnonhSv+7u01EcDJsiedUn+FQMkSb9e+EXZ9mwPR4e88L3oWjlefEuNx5JHm82m5s2ba+LEicrIyFB2drZCQkI0YMAAjRgxwrHdhAkTNGHCBKd9U1JS1LZtW0nKsyI3d+5cx7BsXnx8fHT27Fn16dNHp06dUoUKFfT444/rtddek3TtXsZVq1bp1VdfVatWrWQYhu655x49+eSTLnjn/2fixImKj49XixYtVKFCBb388su6cOGC0zZTp07ViBEj9Ne//lVnz55V9erVHZ9P1apV9dprr+mVV17Rn/70J/Xp0yff+xV69OihZ599Vj4+PuratavTuv79+6tUqVIaP368XnrpJZUuXVoNGzYs0r9SU7dRbU1b+H+z14e8dm2m/Zfzv9LrQ8Z6KizcxD/+sUSB5cvpb68OUeXKlfTDjt3q/NjTOnz4mKdDQx4efLqDJGnwfOfblOYMm6qNC1bltQs8jO9FXGcxuJscLtKsyu+b2AP32nxmn6dDQAE9W6WVp0NAAfzn8glPh4AC+v64+/5wqR/U3GV97Ti1wWV9mXHX3fMIAABQ2HnzsHWhneFQv359p0fP3Lhcf2wNAAAACqbQVh6XLl2q7Oy8b7q+PtMYAADAE5htfRcKDQ31dAgAAAB5YtgaAAAARUKhrTwCAADcrRi2BgAAgGkMWwMAAKBIoPIIAADgZgxbAwAAwDTDyPF0CLeNYWsAAACYRuURAADAzXK8eNiayiMAAABMo/IIAADgZoYXP6qH5BEAAMDNGLYGAABAkUDlEQAAwM0YtgYAAIBp/DwhAAAAigQqjwAAAG7GzxMCAADANG++55FhawAAAJhG5REAAMDNvPk5jySPAAAAbsawNQAAAIoEKo8AAABu5s3PeSR5BAAAcDOGrQEAAFAkUHkEAABwM2ZbAwAAwDSGrQEAAFAkUHkEAABwM2ZbAwAAwDTDi+95ZNgaAAAAplF5BAAAcDOGrQEAAGAas60BAABQJFB5BAAAcDNvnjBD8ggAAOBmDFsDAADAa3zwwQeqUaOGfH19df/992v16tWm9yV5BAAAcDPDMFy2FNT8+fP1wgsv6NVXX9WWLVvUqlUrPfroozp8+LCp/UkeAQAA3Mxw4VJQ77zzjvr166f+/furbt26evfddxUSEqKpU6ea2p/kEQAAwIvZ7XZduHDBabHb7Xlue/nyZaWnp6tDhw5O7R06dNDatWtNHY8JM3CZ74+v8nQILme325WcnKyEhARZrVZPhwMTOGfehfPlfThnrnHl8jGX9ZWYmKjXXnvNqW306NFKTEzMte2ZM2d09epVBQUFObUHBQXp5MmTpo5nMbx5ug9wh124cEEBAQE6f/68ypQp4+lwYALnzLtwvrwP5+zuY7fbc1UarVZrnsn98ePHVbVqVa1du1ZRUVGO9jfeeEOzZs3Srl27bnk8Ko8AAABeLL9EMS8VKlSQj49PripjZmZmrmpkfrjnEQAAoIgoWbKk7r//fi1btsypfdmyZWrRooWpPqg8AgAAFCFDhw7V008/rSZNmigqKkoffvihDh8+rEGDBpnan+QRuAmr1arRo0dzU7gX4Zx5F86X9+Gceb8nn3xSZ8+e1euvv64TJ06oQYMGWrp0qUJDQ03tz4QZAAAAmMY9jwAAADCN5BEAAACmkTwCAADANJJHwAPS0tJksVh07tw5T4eCfLRt21YvvPCCp8PwWomJibrvvvs8HYYOHjwoi8WirVu3ejqUIiU1NVVly5a948fhOvUMkkd4vbi4OFksFo0dO9apffHixbJYLB6KqmjJzMzUwIEDVb16dVmtVgUHBysmJkbr1q2TJIWFhendd9/Nc9/r/7jntaxfv/6Ox55fIv/5558rKSnpjh//TvLkeRk2bJhWrFjhyrdzS3FxceratatTW0hIiGM2qSd58zVyO5588knt2bPHZf0V5uvUG/GoHhQKvr6+GjdunAYOHKhy5cq5pM/Lly+rZMmSLumrsOvevbuys7M1c+ZM1axZU6dOndKKFSv0008/me5j+fLlql+/vlNbYGCgq0M1rXz58h47tqt48rzYbDbZbLYCx+xqPj4+Cg4O9nQYhfIauRk/Pz/5+fnd8eMUhuvUKxmAl+vbt6/xhz/8wahTp44xfPhwR/uiRYuMG/8vvmDBAqNevXpGyZIljdDQUGPChAlO/YSGhhpJSUlG3759jTJlyhh9+vQxUlJSjICAAOOLL74watWqZfj5+Rndu3c3Ll68aKSmphqhoaFG2bJljcGDBxtXrlxx9DVr1izj/vvvN2w2mxEUFGT88Y9/NE6dOuVYv3LlSkOS8fPPP9+5D8ZNfv75Z0OSkZaWlu82oaGhxsSJE/Ncd+DAAUOSsWXLlts6/r59+4zHHnvMqFSpklG6dGmjSZMmxrJly5y2+fXXX43hw4cb1apVM0qWLGmEh4cbf//73x3HvnHp27evYRiG0aZNG+P55583DMMwXnnlFaN58+a5jt2wYUNj1KhRjtcff/yxUadOHcNqtRq1a9c23n///dt6T67g6fMyevRoo1GjRo7Xffv2Nbp06WKMHz/eCA4ONsqXL2/89a9/NS5fvuzY5lbXjWEYxg8//GB07NjR8Pf3N2w2m/Hggw8a+/btM0aPHp3rXK5cudLpfVy9etWoWrWqMXXqVKc+09PTDUlGRkaGYRiGce7cOWPAgAFGxYoVDX9/f6Ndu3bG1q1bb+tzMAzPn4utW7cabdu2NWw2m+Hv729ERkYaGzdudKz/z3/+Y7Rq1crw9fU1qlWrZjz77LPGxYsXnWJLSkoynn76aaN06dJG9erVjcWLFxuZmZnGY489ZpQuXdpo0KCBU5/Xvzuv4zotXBi2RqHg4+OjN998U1OmTNHRo0dzrU9PT1fPnj3Vq1cvbd++XYmJiRo5cqRSU1Odths/frwaNGig9PR0jRw5UpL0yy+/aPLkyZo3b56+/vprpaWl6fHHH9fSpUu1dOlSzZo1Sx9++KEWLFjg6Ofy5ctKSkrStm3btHjxYh04cEBxcXF38iPwmOsVpsWLF8tut7v9+BcvXlTHjh21fPlybdmyRTExMercubMOHz7s2KZPnz6aN2+eJk+erJ07d2ratGmy2WwKCQnRwoULJUm7d+/WiRMnNGnSpFzHiI2N1YYNG5SRkeFo27Fjh7Zv367Y2FhJ0owZM/Tqq6/qjTfe0M6dO/Xmm29q5MiRmjlz5h3+BPLm6fOSl5UrVyojI0MrV67UzJkzlZqa6nQN3uq6OXbsmFq3bi1fX199++23Sk9PV3x8vK5cuaJhw4apZ8+eeuSRR3TixAmdOHEi10+tFStWTL169dLs2bOd2ufMmaOoqCjVrFlThmGoU6dOOnnypJYuXar09HRFRkbq4YcfLlCV8EaePhexsbGqVq2aNm7cqPT0dL3yyisqUaKEJGn79u2KiYnR448/rv/+97+aP3++1qxZo8GDBzv1MXHiRLVs2VJbtmxRp06d9PTTT6tPnz566qmntHnzZoWHh6tPnz4y8nl0NNdpIePp7BX4va5XNAzDMB544AEjPj7eMAznymPv3r2N9u3bO+03fPhwo169eo7XoaGhRteuXZ22SUlJMSQZ+/btc7QNHDjQKFWqlPG///3P0RYTE2MMHDgw3xi///57Q5Jjn8JUeTSMa1XdcuXKGb6+vkaLFi2MhIQEY9u2bY71Zqoqfn5+RunSpZ2WG6u5BVGvXj1jypQphmEYxu7duw1Juaoc1+V3Lm6saBiGYURERBivv/6643VCQoLRtGlTx+uQkBBjzpw5Tn0kJSUZUVFRt/UeXMGT5yWvymNoaKjTvj169DCefPLJfPv47XWTkJBg1KhRw6laeaMbvwt++z6uV+02b95sWCwW4+DBg4ZhGI5q5PXq04oVK4wyZcoYv/76q1M/99xzjzF9+vRbvu/8ePJc+Pv7G6mpqXmue/rpp40///nPTm2rV682ihUrZly6dMkR21NPPeVYf+LECUOSMXLkSEfbunXrDEnGiRMnDMPIXXnMC9ep96LyiEJl3Lhxmjlzpn788Uen9p07d6ply5ZObS1bttTevXt19epVR1uTJk1y9VmqVCndc889jtdBQUEKCwtzup8rKChImZmZjtdbtmxRly5dFBoaKn9/f7Vt21aSnP7KLky6d++u48ePa8mSJYqJiVFaWpoiIyNzVXZvZv78+dq6davT4uPjc8v9srKy9NJLL6levXoqW7asbDabdu3a5fisr/fTpk2b2317kq5VNa5XrAzD0Ny5cx3VjNOnT+vIkSPq16+fo8pks9k0ZswYpyqIu3nyvOSlfv36TvtWrly5QNfN1q1b1apVK0fV7HY0btxYderU0dy5cyVJq1atUmZmpnr27Cnp2ijFxYsXFRgY6HQuDxw48LvOpSfPxdChQ9W/f39FR0dr7NixTu8jPT1dqampTu81JiZGOTk5OnDggGO7iIgIx38HBQVJkho2bJir7cbzeSOu08KFCTMoVFq3bq2YmBiNGDHCabjLMIxcM6+NPIZXSpcunavtt/9QWSyWPNtycnIkXfuS7NChgzp06KBPP/1UFStW1OHDhxUTE6PLly/f7lu76/n6+qp9+/Zq3769Ro0apf79+2v06NGmh+tDQkIUHh5e4OMOHz5c33zzjSZMmKDw8HD5+fnpiSeecHzWrrppv3fv3nrllVe0efNmXbp0SUeOHFGvXr0kyXHuZ8yYoebNmzvtd7uJlqt46rzk5fdeN646l7GxsZozZ45eeeUVzZkzRzExMapQoYKka+eycuXKSktLy7Xf7330jKfORWJionr37q1//etf+uqrrzR69GjNmzdP3bp1U05OjgYOHKjnnnsu137Vq1d3/PeN5+76d2lebdfP529xnRYuJI8odMaOHav77rtPtWrVcrTVq1dPa9ascdpu7dq1qlWrlsu/NHbt2qUzZ85o7NixCgkJkSRt2rTJpcfwBvXq1dPixYvv+HFWr16tuLg4devWTdK1e6sOHjzoWN+wYUPl5ORo1apVio6OzrX/9Rn1N1ag81KtWjW1bt1as2fP1qVLlxQdHe2otgQFBalq1arav3+/o8pxt3LXeSkoM9dNRESEZs6cqezs7DyrjyVLlrzleZSuJRh/+9vflJ6ergULFmjq1KmOdZGRkTp58qSKFy+usLCw3/embsGd56JWrVqqVauWhgwZoj/+8Y9KSUlRt27dFBkZqR07drjsD4T8cJ0WLiSPKHQaNmyo2NhYTZkyxdH24osvqmnTpkpKStKTTz6pdevW6b333tMHH3zg8uNXr15dJUuW1JQpUzRo0CD98MMPhfo5ZGfPnlWPHj0UHx+viIgI+fv7a9OmTXrrrbfUpUsXx3bHjh3L9aDmGysbZ8+e1cmTJ53Wly1bVr6+vjc9fnh4uD7//HN17txZFotFI0eOdKp+hIWFqW/fvoqPj9fkyZPVqFEjHTp0yDFUGRoaKovFoi+//FIdO3aUn59fvo+YiY2NVWJioi5fvqyJEyc6rUtMTNRzzz2nMmXK6NFHH5XdbtemTZv0888/a+jQoTd9D3eCp89LQZm5bgYPHqwpU6aoV69eSkhIUEBAgNavX69mzZqpdu3aCgsL0zfffKPdu3crMDBQAQEBeR6rRo0aatGihfr166crV644fR7R0dGKiopS165dNW7cONWuXVvHjx/X0qVL1bVr1zxvbbkVT56LS5cuafjw4XriiSdUo0YNHT16VBs3blT37t0lSS+//LIeeOABPfPMMxowYIBKly6tnTt3atmyZU7fob8X12kh49lbLoHfL6+b5A8ePGhYrdY8H9VTokQJo3r16sb48eOd9snrhvW8bvr+7USAvGKYM2eOERYWZlitViMqKspYsmSJ0037hWnCzK+//mq88sorRmRkpBEQEGCUKlXKqF27tvG3v/3N+OWXXwzDuPbZ6jeP2pBkpKSk5PkYjuvL3Llzb3n8AwcOGO3atTP8/PyMkJAQ47333st1E/2lS5eMIUOGGJUrV3Y8AuTjjz92rH/99deN4OBgw2Kx5PkIkOt+/vlnw2q15powdd3s2bON++67zyhZsqRRrlw5o3Xr1sbnn39e8A/VBTx9XvJ7VM+Nnn/+eaNNmzaO17e6bgzDMLZt22Z06NDBKFWqlOHv72+0atXK8YidzMxMo3379obNZsvzUT03ev/99w1JRp8+fXLFfuHCBePZZ581qlSpYpQoUcIICQkxYmNjjcOHD9/yfefFk+fCbrcbvXr1MkJCQoySJUsaVapUMQYPHuyYDGMY1yYmXf/cSpcubURERBhvvPGGY31e342SjEWLFjle//Zz/u13J9dp4WIxjHzm1QMAAAC/wWxrAAAAmEbyCOCuVr9+fafHaty4/PZhz3Afzsvdg3MBd2PYGsBd7dChQ8rOzs5zXVBQkPz9/d0cESTOy92EcwF3I3kEAACAaQxbAwAAwDSSRwAAAJhG8ggAAADTSB4BAABgGskjANyFEhMTdd999zlex8XFqWvXrm6P4+DBg7JYLLl+Ng9A0UXyCAAFEBcXJ4vFIovFohIlSqhmzZoaNmyYsrKy7uhxJ02apNTUVFPbkvABuJOKezoAAPA2jzzyiFJSUpSdna3Vq1erf//+ysrK0tSpU522y87OVokSJVxyzICAAJf0AwC/F5VHACggq9Wq4OBghYSEqHfv3oqNjdXixYsdQ80ff/yxatasKavVKsMwdP78ef35z39WpUqVVKZMGT300EPatm2bU59jx451PNC5X79++vXXX53W/3bYOicnR+PGjVN4eLisVquqV6+uN954Q5JUo0YNSVLjxo1lsVjUtm1bx34pKSmqW7eufH19VadOHX3wwQdOx/n+++/VuHFj+fr6qkmTJtqyZYsLPzkAhQGVRwD4nfz8/By/8LFv3z599tlnWrhwoXx8fCRJnTp1Uvny5bV06VIFBARo+vTpevjhh7Vnzx6VL19en332mUaPHq33339frVq10qxZszR58mTVrFkz32MmJCRoxowZmjhxoh588EGdOHFCu3btknQtAWzWrJmWL1+u+vXrq2TJkpKkGTNmaPTo0XrvvffUuHFjbdmyRQMGDFDp0qXVt29fZWVl6Q9/+IMeeughffrppzpw4ICef/75O/zpAfA6BgDAtL59+xpdunRxvN6wYYMRGBho9OzZ0xg9erRRokQJIzMz07F+xYoVRpkyZYxff/3VqZ977rnHmD59umEYhhEVFWUMGjTIaX3z5s2NRo0a5XncCxcuGFar1ZgxY0aeMR44cMCQZGzZssWpPSQkxJgzZ45TW1JSkhEVFWUYhmFMnz7dKF++vJGVleVYP3Xq1Dz7AlB0MWwNAAX05ZdfymazydfXV1FRUWrdurWmTJkiSQoNDVXFihUd26anp+vixYsKDAyUzWZzLAcOHFBGRoYkaefOnYqKinI6xm9f32jnzp2y2+16+OGHTcd8+vRpHTlyRP369XOKY8yYMU5xNGrUSKVKlTIVB4CiiWFrACigdu3aaerUqSpRooSqVKniNCmmdOnSTtvm5OSocuXKSktLy9VP2bJlb+v4fn5+Bd4nJydH0rWh6+bNmzutuz68bhjGbcUDoGgheQSAAipdurTCw8NNbRsZGamTJ0+qePHiCgsLy3ObunXrav369erTp4+jbf369fn2ee+998rPz08rVqxQ//79c62/fo/j1atXHW1BQUGqWrWq9u/fr9jY2Dz7rVevnmbNmqVLly45EtSbxQGgaGLYGgDuoOjoaEVFRalr16765ptvdPDgQa1du1Z/+9vftGnTJknS888/r48//lgff/yx9uzZo9GjR2vHjh359unr66uXX35ZL730kj755BNlZGRo/fr1+uijjyRJlSpVkp+fn77++mudOnVK58+fl3TtwePJycmaNGmS9uzZo+3btyslJUXvvPOOJKl3794qVqyY+vXrpx9//FFLly7VhAkT7vAnBMDbkDwCwB1ksVi0dOlStW7dWvHx8apVq5Z69eqlgwcPKigoSJL05JNPatSoUXr55Zd1//3369ChQ/rLX/5y035HjhypF198UaNGjVLdunX15JNPKjMzU5JUvHhxTZ48WdOnT1eVKlXUpUsXSVL//v3197//XampqWrYsKHatGmj1NRUx6N9bDabvvjiC/34449q3LixXn31VY0bN+4OfjoAvJHF4CYXAAAAmETlEQAAAKaRPAIAAMA0kkcAAACYRvIIAAAA00geAQAAYBrJIwAAAEwjeQQAAIBpJI8AAAAwjeQRAAAAppE8AgAAwDSSRwAAAJj2/wAaU1LY2eQPPQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 700x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the confusion matrix with the label name before encoding as the labels\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels = label_encoder.classes_, yticklabels = label_encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Normal       0.40      0.67      0.50         3\n",
      "    SLE_active       1.00      0.50      0.67         2\n",
      "  SLE_inactive       0.70      0.88      0.78         8\n",
      "SLE_semiactive       1.00      0.25      0.40         4\n",
      "\n",
      "      accuracy                           0.65        17\n",
      "     macro avg       0.77      0.57      0.59        17\n",
      "  weighted avg       0.75      0.65      0.63        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the classification report\n",
    "label_map = {i: label for i, label in enumerate(label_encoder.classes_)} # Encoding back to original labels\n",
    "y_pred_labels = [label_map[pred] for pred in y_pred]\n",
    "y_test_labels = [label_map[true] for true in y_test]\n",
    "\n",
    "report = classification_report(y_test_labels, y_pred_labels)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.6521739130434783\n"
     ]
    }
   ],
   "source": [
    "# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) to calculate specificity\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test_labels, y_pred_labels)\n",
    "TN = support[0] - fscore[0]\n",
    "FP = support[1] - fscore[1]\n",
    "FN = support[0] - fscore[0]\n",
    "TP = support[1] - fscore[1]\n",
    "\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The voting classifier model achieved an accuracy of approximately 64.71% on the given dataset. This means that the model was able to correctly classify about 65% of the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label \"Normal\":  \n",
    "Precision: 40% - Out of all samples predicted as \"Normal,\" only 40% were actually correct.  \n",
    "Recall: 67% - The model was able to identify 67% of the actual \"Normal\" samples.  \n",
    "F1-score: 50% - The harmonic mean of precision and recall for the \"Normal\" class is 50%.  \n",
    "\n",
    "Label \"SLE_active\":  \n",
    "Precision: 100% - The model achieved perfect precision for predicting \"SLE_active\" class.  \n",
    "Recall: 50% - Only half of the actual \"SLE_active\" samples were correctly identified by the model.  \n",
    "F1-score: 67% - The F1-score for the \"SLE_active\" class is 67%.  \n",
    "\n",
    "Label \"SLE_inactive\":  \n",
    "Precision: 70% - 70% of the samples predicted as \"SLE_inactive\" were actually correct.  \n",
    "Recall: 88% - The model successfully identified 88% of the actual \"SLE_inactive\" samples.  \n",
    "F1-score: 78% - The F1-score for the \"SLE_inactive\" class is 78%.  \n",
    "\n",
    "Label \"SLE_semiactive\":  \n",
    "Precision: 100% - The model achieved perfect precision for predicting \"SLE_semiactive\" class.  \n",
    "Recall: 25% - Only a quarter of the actual \"SLE_semiactive\" samples were correctly identified by the model.  \n",
    "F1-score: 40% - The F1-score for the \"SLE_semiactive\" class is 40%.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
